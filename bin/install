#!/bin/bash

# Optimized Secrets Store CSI Driver and External Secrets Operator Management Script
# This script configures the Red Hat Secrets Store CSI Driver system operator and installs the Azure provider

set -euo pipefail

# Source configuration (if it exists)
# Suppress echo output from config.env unless it's show or validate command
COMMAND_PREVIEW="${1:-}"
if [[ "$COMMAND_PREVIEW" == "show" ]] || [[ "$COMMAND_PREVIEW" == "validate" ]]; then
    # Show config output for show/validate commands
    if [ -f "$(dirname "${BASH_SOURCE[0]}")/../config.env" ]; then
        source "$(dirname "${BASH_SOURCE[0]}")/../config.env"
    fi
else
    # Suppress config output for all other commands
    if [ -f "$(dirname "${BASH_SOURCE[0]}")/../config.env" ]; then
        source "$(dirname "${BASH_SOURCE[0]}")/../config.env" >/dev/null 2>&1
    fi
fi

# Colors for output (needed for check_cluster_auth)
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Helper functions
print_error() {
    echo -e "${RED}❌${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}⚠️${NC} $1"
}

print_info() {
    echo -e "${CYAN}ℹ️${NC} $1"
}

print_success() {
    echo -e "${GREEN}✅${NC} $1"
}

# Check cluster authentication and permissions
check_cluster_auth() {
    # Check if oc is authenticated
    if ! oc whoami &>/dev/null; then
        print_error "Not authenticated to OpenShift cluster"
        print_info "Please authenticate using: oc login"
        return 1
    fi
    
    local current_user=$(oc whoami 2>/dev/null || echo "")
    print_info "Authenticated as: ${current_user}"
    
    # Check if user has cluster-admin permissions
    # Verify by checking if user can access cluster-scoped resources
    local has_cluster_access=false
    
    # Try to check permissions using oc auth can-i
    if oc auth can-i get clustercsidriver --all-namespaces &>/dev/null; then
        has_cluster_access=true
    elif oc auth can-i get csidriver --all-namespaces &>/dev/null; then
        has_cluster_access=true
    elif oc auth can-i '*' '*' --all-namespaces &>/dev/null 2>&1 | grep -q "yes"; then
        has_cluster_access=true
    fi
    
    # Fallback: Try to actually access a cluster-scoped resource
    if [ "$has_cluster_access" = false ]; then
        if oc get clustercsidriver &>/dev/null || oc get csidriver &>/dev/null || oc get namespace &>/dev/null; then
            has_cluster_access=true
        fi
    fi
    
    if [ "$has_cluster_access" = false ]; then
        print_warning "User '${current_user}' may not have cluster-admin permissions"
        print_info "Some operations may fail. Recommended: use a cluster-admin user"
        print_info "You can continue, but operations requiring cluster-scoped access may fail"
        # Continue anyway - let operations fail with clear errors
    else
        print_success "Cluster permissions verified"
    fi
    
    return 0
}

# Fetch Azure account information dynamically
fetch_azure_account_info() {
    if ! az account show &>/dev/null; then
        return 1
    fi
    
    # Fetch subscription ID from Azure CLI
    AZURE_SUBSCRIPTION_ID="${AZURE_SUBSCRIPTION_ID:-$(az account show --query id -o tsv 2>/dev/null || echo '')}"
    
    # Fetch tenant ID from Azure CLI
    AZURE_TENANT_ID="${AZURE_TENANT_ID:-$(az account show --query tenantId -o tsv 2>/dev/null || echo '')}"
    
    export AZURE_SUBSCRIPTION_ID
    export AZURE_TENANT_ID
    
    return 0
}

# Fetch Key Vault information from Azure by prefix
fetch_keyvault_by_prefix() {
    local prefix="${AZURE_RESOURCE_PREFIX:-aro-secrets-}"
    local rg="${AZURE_RESOURCE_GROUP:-}"
    
    if [ -z "$rg" ]; then
        return 1
    fi
    
    # List Key Vaults in the resource group and find one with the prefix
    local kv_name=$(az keyvault list --resource-group "$rg" --query "[?starts_with(name, '${prefix}')].name" -o tsv 2>/dev/null | head -1)
    
    if [ -n "$kv_name" ] && [ "$kv_name" != "" ]; then
        export ACTUAL_KEYVAULT_NAME="$kv_name"
        export KEYVAULT_URL="https://${kv_name}.vault.azure.net/"
        # Extract base name (remove prefix)
        export KEYVAULT_NAME="${kv_name#${prefix}}"
        return 0
    fi
    
    return 1
}

# Initialize Azure values from CLI (call this early in the script)
initialize_azure_values() {
    # Fetch Azure account info
    fetch_azure_account_info
    
    # Set defaults for user-configurable values (if not in config.env)
    export AZURE_RESOURCE_PREFIX="${AZURE_RESOURCE_PREFIX:-aro-secrets-}"
    export KEYVAULT_NAME="${KEYVAULT_NAME:-akv-01}"
    export SERVICE_PRINCIPAL_NAME="${SERVICE_PRINCIPAL_NAME:-csi-driver-sp}"
    
    # Try to fetch Key Vault from Azure if resource group is known
    if [ -n "${AZURE_RESOURCE_GROUP:-}" ]; then
        if fetch_keyvault_by_prefix; then
            print_info "Found Key Vault from Azure: ${ACTUAL_KEYVAULT_NAME}"
        else
            # Construct expected name if not found
            export ACTUAL_KEYVAULT_NAME="${AZURE_RESOURCE_PREFIX}${KEYVAULT_NAME}"
            export KEYVAULT_URL="https://${ACTUAL_KEYVAULT_NAME}.vault.azure.net/"
        fi
    else
        # Construct expected name if resource group not known yet
        export ACTUAL_KEYVAULT_NAME="${AZURE_RESOURCE_PREFIX}${KEYVAULT_NAME}"
        export KEYVAULT_URL="https://${ACTUAL_KEYVAULT_NAME}.vault.azure.net/"
    fi
    
    # Construct Service Principal name
    export ACTUAL_SERVICE_PRINCIPAL_NAME="${AZURE_RESOURCE_PREFIX}${SERVICE_PRINCIPAL_NAME}"
}

# Default installation options
INSTALL_SSCSI=true
INSTALL_ESO=false
INSTALL_AZURE_PROVIDER=true

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Helper functions
print_header() {
    echo -e "${CYAN}================================${NC}"
    echo -e "${CYAN}$1${NC}"
    echo -e "${CYAN}================================${NC}"
}

print_status() {
    echo -e "${YELLOW}➤${NC} $1"
}


# Parse command line arguments
parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --sscsi)
                INSTALL_SSCSI=true
                INSTALL_AZURE_PROVIDER=true  # Always install Azure provider with SSCSI
                INSTALL_ESO=false
                shift
                ;;
            --eso)
                INSTALL_SSCSI=false
                INSTALL_AZURE_PROVIDER=false
                INSTALL_ESO=true
                shift
                ;;
            --all)
                INSTALL_SSCSI=true
                INSTALL_ESO=true
                INSTALL_AZURE_PROVIDER=true
                shift
                ;;
            --help|-h)
                show_help
                exit 0
                ;;
            *)
                print_error "Unknown option: $1"
                print_error "Valid options for 'operator' command are: --sscsi, --eso, --all, --help"
                show_help
                exit 1
                ;;
        esac
    done
}

# Check prerequisites
check_prerequisites() {
    print_header "Checking Prerequisites"
    
    # Check if oc is available
    if ! command -v oc &> /dev/null; then
        print_error "oc command not found. Please install OpenShift CLI."
        exit 1
    fi
    
    # Check if envsubst is available
    if ! command -v envsubst &> /dev/null; then
        print_error "envsubst command not found. Please install gettext."
        exit 1
    fi
    
    # Check cluster connectivity
    if ! oc cluster-info &> /dev/null; then
        print_error "Cannot connect to OpenShift cluster. Please check your kubeconfig."
        exit 1
    fi
    
    print_success "All prerequisites met!"
}

# Refresh Azure authentication if needed
refresh_azure_auth() {
    print_status "Checking Azure authentication status..."
    
    # Check if we can access Azure resources
    if az account show &> /dev/null && az group show --name "${AZURE_RESOURCE_GROUP}" &> /dev/null; then
        print_success "Azure authentication is working"
        return 0
    fi
    
    print_warning "Azure authentication issues detected. Attempting to refresh..."
    
    # Try to refresh token
    if az account get-access-token &> /dev/null; then
        print_success "Azure token refreshed successfully"
        return 0
    fi
    
    # Try interactive login
    print_status "Attempting interactive login..."
    if az login --scope https://graph.microsoft.com/.default --only-show-errors; then
        print_success "Azure login successful"
        return 0
    fi
    
    print_error "Failed to refresh Azure authentication"
    print_info "Please run 'az login' manually to authenticate"
    return 1
}

# Validate Key Vault name against Azure requirements
# Azure Key Vault names must be:
# - 3-24 characters long
# - Begin with a letter
# - End with a letter or digit
# - Only alphanumeric characters and hyphens
# - No consecutive hyphens
validate_keyvault_name() {
    local name="$1"
    local errors=()
    
    # Check length
    local length=${#name}
    if [ $length -lt 3 ]; then
        errors+=("Key Vault name must be at least 3 characters (currently ${length})")
    elif [ $length -gt 24 ]; then
        errors+=("Key Vault name must be at most 24 characters (currently ${length}): '${name}'")
    fi
    
    # Check first character
    if ! [[ "${name:0:1}" =~ ^[a-zA-Z]$ ]]; then
        errors+=("Key Vault name must begin with a letter")
    fi
    
    # Check last character
    if ! [[ "${name: -1}" =~ ^[a-zA-Z0-9]$ ]]; then
        errors+=("Key Vault name must end with a letter or digit")
    fi
    
    # Check for invalid characters and consecutive hyphens
    if [[ "$name" =~ [^a-zA-Z0-9-] ]]; then
        errors+=("Key Vault name contains invalid characters (only alphanumeric and hyphens allowed)")
    fi
    
    if [[ "$name" =~ -- ]]; then
        errors+=("Key Vault name cannot contain consecutive hyphens")
    fi
    
    if [ ${#errors[@]} -gt 0 ]; then
        print_error "Key Vault name validation failed:"
        for error in "${errors[@]}"; do
            print_error "  - $error"
        done
        print_info ""
        print_info "Azure Key Vault naming requirements:"
        print_info "  - 3-24 characters"
        print_info "  - Begin with a letter"
        print_info "  - End with a letter or digit"
        print_info "  - Only alphanumeric characters and hyphens"
        print_info "  - No consecutive hyphens"
        print_info ""
        print_warning "Current configuration:"
        print_warning "  Prefix: ${AZURE_RESOURCE_PREFIX}"
        print_warning "  Base name: ${KEYVAULT_NAME}"
        print_warning "  Combined: ${name}"
        print_info ""
        print_info "Suggested fixes:"
        print_info "  1. Reduce the length of KEYVAULT_NAME in config.env"
        print_info "  2. Reduce the length of AZURE_RESOURCE_PREFIX"
        print_info "  3. Use a shorter base name"
        return 1
    fi
    
    return 0
}

# Fetch Service Principal information from Azure by display name
# Returns: client_id via stdout, sets success status
fetch_service_principal_info() {
    local sp_name="$1"
    local sp_client_id=""
    
    # Try to find Service Principal by display name (with timeout)
    sp_client_id=$(timeout 10 bash -c "az ad sp list \
        --display-name \"${sp_name}\" \
        --query '[0].appId' \
        -o tsv 2>/dev/null || echo ''")
    
    if [ -n "${sp_client_id}" ] && [ "${sp_client_id}" != "null" ] && [ "${sp_client_id}" != "" ]; then
        echo "${sp_client_id}"
        return 0
    fi
    
    # If not found, try using the client ID from config if it's valid
    if [ -n "${SERVICE_PRINCIPAL_CLIENT_ID:-}" ]; then
        if timeout 5 az ad sp show --id "${SERVICE_PRINCIPAL_CLIENT_ID}" &>/dev/null; then
            echo "${SERVICE_PRINCIPAL_CLIENT_ID}"
            return 0
        fi
    fi
    
    return 1
}

# Fetch Key Vault information from Azure
# Sets ACTUAL_KEYVAULT_NAME and KEYVAULT_URL if Key Vault exists
fetch_keyvault_info() {
    local kv_name="$1"
    local rg="$2"
    
    if az keyvault show --name "${kv_name}" --resource-group "${rg}" &>/dev/null; then
        export ACTUAL_KEYVAULT_NAME="${kv_name}"
        export KEYVAULT_URL="https://${kv_name}.vault.azure.net/"
        return 0
    fi
    
    return 1
}

# Setup Azure resources
setup_azure_resources() {
    print_header "Setting Up Azure Resources"
    
    # Set default resource prefix if not defined
    export AZURE_RESOURCE_PREFIX="${AZURE_RESOURCE_PREFIX:-aro-secrets-}"
    
    # Construct actual resource names with prefix
    export ACTUAL_KEYVAULT_NAME="${AZURE_RESOURCE_PREFIX}${KEYVAULT_NAME}"
    export ACTUAL_SERVICE_PRINCIPAL_NAME="${AZURE_RESOURCE_PREFIX}${SERVICE_PRINCIPAL_NAME}"
    
    # Validate Key Vault name before proceeding
    print_status "Validating Key Vault name..."
    if ! validate_keyvault_name "${ACTUAL_KEYVAULT_NAME}"; then
        print_error "Cannot proceed with Key Vault creation - name does not meet Azure requirements"
        exit 1
    fi
    
    # Generate Key Vault URL from actual name (will be updated if Key Vault exists)
    export KEYVAULT_URL="https://${ACTUAL_KEYVAULT_NAME}.vault.azure.net/"
    
    print_success "Key Vault name validation passed"
    print_info "Resource prefix: ${AZURE_RESOURCE_PREFIX}"
    print_info "Key Vault will be created as: ${ACTUAL_KEYVAULT_NAME} (${#ACTUAL_KEYVAULT_NAME} chars)"
    print_info "Service Principal will be created as: ${ACTUAL_SERVICE_PRINCIPAL_NAME}"
    
    # Check Azure CLI authentication
    print_status "Checking Azure CLI authentication..."
    if ! az account show &> /dev/null; then
        print_error "Azure CLI not authenticated. Attempting to refresh authentication..."
        if ! refresh_azure_auth; then
            print_error "Azure CLI authentication failed. Please run 'az login' first."
            exit 1
        fi
    fi
    
    # Fetch current subscription and tenant from Azure CLI
    CURRENT_SUB=$(az account show --query id -o tsv)
    CURRENT_TENANT=$(az account show --query tenantId -o tsv)
    
    # Update from Azure CLI if different
    if [ -n "${CURRENT_SUB}" ] && [ "${CURRENT_SUB}" != "${AZURE_SUBSCRIPTION_ID:-}" ]; then
        print_status "Updating subscription ID from Azure CLI: ${CURRENT_SUB}"
        export AZURE_SUBSCRIPTION_ID="${CURRENT_SUB}"
    fi
    
    if [ -n "${CURRENT_TENANT}" ] && [ "${CURRENT_TENANT}" != "${AZURE_TENANT_ID:-}" ]; then
        print_status "Updating tenant ID from Azure CLI: ${CURRENT_TENANT}"
        export AZURE_TENANT_ID="${CURRENT_TENANT}"
    fi
    
    # Verify we're in the correct subscription (if explicitly set in config)
    if [ -n "${AZURE_SUBSCRIPTION_ID:-}" ] && [ "${CURRENT_SUB}" != "${AZURE_SUBSCRIPTION_ID}" ]; then
        print_error "Azure CLI is authenticated to subscription ${CURRENT_SUB}, but config expects ${AZURE_SUBSCRIPTION_ID}"
        print_info "Please run: az account set --subscription ${AZURE_SUBSCRIPTION_ID}"
        exit 1
    fi
    
    print_success "Azure CLI authenticated to correct subscription"
    
    # Fetch or create Service Principal
    print_status "Fetching Service Principal information from Azure..."
    # Save original value before fetching
    local original_sp_id="${SERVICE_PRINCIPAL_CLIENT_ID:-}"
    FETCHED_SP_CLIENT_ID=$(fetch_service_principal_info "${ACTUAL_SERVICE_PRINCIPAL_NAME}" 2>/dev/null || echo "")
    
    if [ -n "${FETCHED_SP_CLIENT_ID}" ] && [ "${FETCHED_SP_CLIENT_ID}" != "" ]; then
        print_success "Found existing Service Principal: ${FETCHED_SP_CLIENT_ID}"
        export SERVICE_PRINCIPAL_CLIENT_ID="${FETCHED_SP_CLIENT_ID}"
        # Update config.env if value changed (check against original value before we overwrote it)
        if [ -w "config.env" ] && [ -n "${original_sp_id}" ] && [ "${FETCHED_SP_CLIENT_ID}" != "${original_sp_id}" ]; then
            print_status "Updating config.env with Service Principal Client ID..."
            if [[ "$OSTYPE" == "darwin"* ]]; then
                sed -i '' "s|export SERVICE_PRINCIPAL_CLIENT_ID=.*|export SERVICE_PRINCIPAL_CLIENT_ID=\"${FETCHED_SP_CLIENT_ID}\"|" config.env 2>/dev/null || true
            else
                sed -i "s|export SERVICE_PRINCIPAL_CLIENT_ID=.*|export SERVICE_PRINCIPAL_CLIENT_ID=\"${FETCHED_SP_CLIENT_ID}\"|" config.env 2>/dev/null || true
            fi
            print_success "Updated config.env"
        fi
    elif [ -n "${SERVICE_PRINCIPAL_CLIENT_ID:-}" ]; then
        print_warning "Could not fetch Service Principal from Azure (may be due to authentication issues)"
        print_info "Using Service Principal Client ID from config.env: ${SERVICE_PRINCIPAL_CLIENT_ID}"
        # Verify the one from config exists
        if ! timeout 5 az ad sp show --id "${SERVICE_PRINCIPAL_CLIENT_ID}" &>/dev/null; then
            print_warning "Service Principal from config.env does not exist or is not accessible"
            print_warning "Will attempt to create a new Service Principal..."
            # Continue to creation logic below
        else
            print_success "Service Principal from config.env is valid"
            # Use the one from config, skip creation
            # No need to update config.env since we're using the value from there
        fi
    fi
    
    # Create Service Principal if we don't have a valid one
    if [ -z "${SERVICE_PRINCIPAL_CLIENT_ID:-}" ] || ! timeout 5 az ad sp show --id "${SERVICE_PRINCIPAL_CLIENT_ID:-invalid}" &>/dev/null 2>&1; then
        print_warning "Service Principal not found. Attempting to create..."
        print_status "Creating service principal for Key Vault access..."
        print_warning "This may take a moment or may fail due to authentication issues..."
        
        # Create Service Principal using variable assignment pattern (like user example)
        print_status "Creating Service Principal: ${ACTUAL_SERVICE_PRINCIPAL_NAME}..."
        
        # Create Service Principal without role assignment first (can assign roles later)
        # Use the variable assignment pattern: VARIABLE="$(command --query 'field' -o tsv)"
        # Note: We create it once and get both appId and password from the single JSON output
        print_info "Creating Service Principal (role assignment will be done separately)..."
        local sp_json=$(timeout 30 bash -c "az ad sp create-for-rbac \
            --name \"${ACTUAL_SERVICE_PRINCIPAL_NAME}\" \
            --skip-assignment \
            --output json 2>&1" || echo "")
        
        if [ -n "$sp_json" ] && echo "$sp_json" | jq -e '.appId' >/dev/null 2>&1; then
            # Extract both values from the JSON response using variable assignment pattern
            SERVICE_PRINCIPAL_CLIENT_ID=$(echo "$sp_json" | jq -r '.appId' 2>/dev/null || echo "")
            SERVICE_PRINCIPAL_CLIENT_SECRET=$(echo "$sp_json" | jq -r '.password' 2>/dev/null || echo "")
            print_success "Service Principal created, extracted credentials from JSON output"
        else
            # Fallback: If JSON parsing fails, try to find existing or use alternative method
            print_warning "JSON output parsing failed, checking if Service Principal already exists..."
            SERVICE_PRINCIPAL_CLIENT_ID=$(timeout 10 bash -c "az ad sp list --display-name \"${ACTUAL_SERVICE_PRINCIPAL_NAME}\" --query '[0].appId' -o tsv 2>&1" || echo "")
            
            if [ -n "${SERVICE_PRINCIPAL_CLIENT_ID}" ] && [ "${SERVICE_PRINCIPAL_CLIENT_ID}" != "" ] && [ "${SERVICE_PRINCIPAL_CLIENT_ID}" != "None" ]; then
                print_warning "Service Principal already exists, resetting credentials..."
                SERVICE_PRINCIPAL_CLIENT_SECRET=$(timeout 10 bash -c "az ad sp credential reset --id \"${SERVICE_PRINCIPAL_CLIENT_ID}\" --query 'password' -o tsv 2>&1" || echo "")
            else
                print_warning "Could not create or find Service Principal"
                SERVICE_PRINCIPAL_CLIENT_ID=""
                SERVICE_PRINCIPAL_CLIENT_SECRET=""
            fi
        fi
        
        # Validate that we got valid values
        if [ -n "${SERVICE_PRINCIPAL_CLIENT_ID}" ] && [ -n "${SERVICE_PRINCIPAL_CLIENT_SECRET}" ] && 
           [ "${SERVICE_PRINCIPAL_CLIENT_ID}" != "" ] && [ "${SERVICE_PRINCIPAL_CLIENT_SECRET}" != "" ] &&
           ! echo "${SERVICE_PRINCIPAL_CLIENT_ID}" | grep -qiE "error|ERROR|timeout|Timeout" &&
           ! echo "${SERVICE_PRINCIPAL_CLIENT_SECRET}" | grep -qiE "error|ERROR|timeout|Timeout"; then
            print_success "Service Principal created successfully: ${SERVICE_PRINCIPAL_CLIENT_ID}"
            export SERVICE_PRINCIPAL_CLIENT_ID
            export SERVICE_PRINCIPAL_CLIENT_SECRET
            
            # Update config.env with new values
            if [ -w "config.env" ]; then
                print_status "Updating config.env with new service principal credentials..."
                if [[ "$OSTYPE" == "darwin"* ]]; then
                    sed -i '' "s|export SERVICE_PRINCIPAL_CLIENT_ID=.*|export SERVICE_PRINCIPAL_CLIENT_ID=\"${SERVICE_PRINCIPAL_CLIENT_ID}\"|" config.env 2>/dev/null || true
                    sed -i '' "s|export SERVICE_PRINCIPAL_CLIENT_SECRET=.*|export SERVICE_PRINCIPAL_CLIENT_SECRET=\"${SERVICE_PRINCIPAL_CLIENT_SECRET}\"|" config.env 2>/dev/null || true
                else
                    sed -i "s|export SERVICE_PRINCIPAL_CLIENT_ID=.*|export SERVICE_PRINCIPAL_CLIENT_ID=\"${SERVICE_PRINCIPAL_CLIENT_ID}\"|" config.env 2>/dev/null || true
                    sed -i "s|export SERVICE_PRINCIPAL_CLIENT_SECRET=.*|export SERVICE_PRINCIPAL_CLIENT_SECRET=\"${SERVICE_PRINCIPAL_CLIENT_SECRET}\"|" config.env 2>/dev/null || true
                fi
                print_success "Updated config.env with new service principal credentials"
            fi
        else
            print_warning "Service Principal creation failed or timed out"
            if [ -n "${SERVICE_PRINCIPAL_CLIENT_ID}" ]; then
                print_info "Error output: ${SERVICE_PRINCIPAL_CLIENT_ID}"
            fi
            SERVICE_PRINCIPAL_CLIENT_ID=""
            SERVICE_PRINCIPAL_CLIENT_SECRET=""
        fi
        
        if [ -z "${SERVICE_PRINCIPAL_CLIENT_ID:-}" ] || [ -z "${SERVICE_PRINCIPAL_CLIENT_SECRET:-}" ]; then
            print_error "Failed to create Service Principal (authentication issue). Please create manually:"
            print_info "Run these commands to create and capture the credentials:"
            print_info "SERVICE_PRINCIPAL_CLIENT_ID=\"\$(az ad sp create-for-rbac --name '${ACTUAL_SERVICE_PRINCIPAL_NAME}' --skip-assignment --query 'appId' -o tsv)\""
            print_info "SERVICE_PRINCIPAL_CLIENT_SECRET=\"\$(az ad sp create-for-rbac --name '${ACTUAL_SERVICE_PRINCIPAL_NAME}' --skip-assignment --query 'password' -o tsv)\""
            print_info "Or create once and extract both:"
            print_info "SP_JSON=\$(az ad sp create-for-rbac --name '${ACTUAL_SERVICE_PRINCIPAL_NAME}' --skip-assignment --output json)"
            print_info "SERVICE_PRINCIPAL_CLIENT_ID=\$(echo \"\$SP_JSON\" | jq -r '.appId')"
            print_info "SERVICE_PRINCIPAL_CLIENT_SECRET=\$(echo \"\$SP_JSON\" | jq -r '.password')"
            print_info "Then update config.env with these values"
            exit 1
        fi
    fi
    
    # Ensure we have a valid Service Principal Client ID before proceeding
    if [ -z "${SERVICE_PRINCIPAL_CLIENT_ID:-}" ]; then
        print_error "Cannot proceed without a valid Service Principal Client ID"
        print_info "Please create the Service Principal manually and update config.env, or run:"
        print_info "az ad sp create-for-rbac --name '${ACTUAL_SERVICE_PRINCIPAL_NAME}' --role 'Key Vault Secrets User' --scopes '/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}'"
        exit 1
    fi
    
    # Verify Service Principal is accessible
    if ! timeout 5 az ad sp show --id "${SERVICE_PRINCIPAL_CLIENT_ID}" &>/dev/null; then
        print_error "Service Principal ${SERVICE_PRINCIPAL_CLIENT_ID} is not accessible"
        print_info "This may be due to authentication issues or the Service Principal does not exist"
        print_info "Please verify the Service Principal exists: az ad sp show --id ${SERVICE_PRINCIPAL_CLIENT_ID}"
        exit 1
    fi
    
    # Fetch or create Key Vault
    print_status "Checking Key Vault..."
    
    # Check if Key Vault already exists (fetch from Azure)
    if fetch_keyvault_info "${ACTUAL_KEYVAULT_NAME}" "${AZURE_RESOURCE_GROUP}"; then
        print_success "Key Vault already exists: ${ACTUAL_KEYVAULT_NAME}"
        print_info "Key Vault URL: ${KEYVAULT_URL}"
    else
        # Create Key Vault with prefixed name
        az keyvault create \
            --name "${ACTUAL_KEYVAULT_NAME}" \
            --resource-group "${AZURE_RESOURCE_GROUP}" \
            --location "${AZURE_LOCATION}" \
            --sku standard \
            --enable-rbac-authorization true \
            --only-show-errors
        
        print_success "Key Vault created"
    fi
    
    # Grant RBAC roles to Service Principal if Key Vault uses RBAC authorization
    print_status "Granting RBAC roles to Service Principal..."
    local rbac_enabled=$(az keyvault show --name "${ACTUAL_KEYVAULT_NAME}" --resource-group "${AZURE_RESOURCE_GROUP}" --query "properties.enableRbacAuthorization" -o tsv 2>/dev/null || echo "false")
    
    if [ "$rbac_enabled" = "true" ]; then
        print_info "Key Vault uses RBAC authorization, assigning roles..."
        
        # Assign Key Vault Secrets User role
        if az role assignment create \
            --assignee "${SERVICE_PRINCIPAL_CLIENT_ID}" \
            --role "Key Vault Secrets User" \
                        --scope "/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${ACTUAL_KEYVAULT_NAME}" \
            --only-show-errors; then
            print_success "Key Vault Secrets User role assigned"
        else
            print_warning "Failed to assign Key Vault Secrets User role"
        fi
        
        # Assign Key Vault Secrets Officer role (for secret creation)
        if az role assignment create \
            --assignee "${SERVICE_PRINCIPAL_CLIENT_ID}" \
            --role "Key Vault Secrets Officer" \
                        --scope "/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${ACTUAL_KEYVAULT_NAME}" \
            --only-show-errors; then
            print_success "Key Vault Secrets Officer role assigned to Service Principal"
        else
            print_warning "Failed to assign Key Vault Secrets Officer role to Service Principal (may already be assigned)"
        fi
        
        # Assign Key Vault Certificate User role (for certificate reading)
        if az role assignment create \
            --assignee "${SERVICE_PRINCIPAL_CLIENT_ID}" \
            --role "Key Vault Certificate User" \
                        --scope "/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${ACTUAL_KEYVAULT_NAME}" \
            --only-show-errors; then
            print_success "Key Vault Certificate User role assigned to Service Principal"
        else
            print_warning "Failed to assign Key Vault Certificate User role to Service Principal (may already be assigned)"
        fi
        
        # Assign Key Vault Crypto User role (for key reading)
        if az role assignment create \
            --assignee "${SERVICE_PRINCIPAL_CLIENT_ID}" \
            --role "Key Vault Crypto User" \
                        --scope "/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${ACTUAL_KEYVAULT_NAME}" \
            --only-show-errors; then
            print_success "Key Vault Crypto User role assigned to Service Principal"
        else
            print_warning "Failed to assign Key Vault Crypto User role to Service Principal (may already be assigned)"
        fi
        
        # Also assign role to current user (for script operations and Key Vault management)
        print_status "Assigning roles to current user (for Key Vault management)..."
        local current_user=$(az account show --query user.name -o tsv 2>/dev/null || echo "")
        local kv_scope="/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${ACTUAL_KEYVAULT_NAME}"
        
        if [ -n "$current_user" ]; then
            # Check if user already has the role
            local user_has_role=$(az role assignment list \
                --assignee "$current_user" \
                --scope "${kv_scope}" \
                --query "[?roleDefinitionName=='Key Vault Secrets Officer'].roleDefinitionName" \
                -o tsv 2>/dev/null || echo "")
            
            if [ -z "$user_has_role" ]; then
                if az role assignment create \
                    --assignee "$current_user" \
                    --role "Key Vault Secrets Officer" \
                    --scope "${kv_scope}" \
                    --only-show-errors 2>/dev/null; then
                    print_success "Key Vault Secrets Officer role assigned to current user: $current_user"
                else
                    print_warning "Failed to assign role to current user (you may need to assign it manually)"
                    print_info "Manual command: az role assignment create --assignee '$current_user' --role 'Key Vault Secrets Officer' --scope '${kv_scope}'"
                fi
            else
                print_info "Current user already has Key Vault Secrets Officer role"
            fi
            
            # Also assign Key Vault Crypto Officer role for creating keys
            local current_user_crypto=$(az role assignment list \
                --scope "${kv_scope}" \
                --assignee "${current_user}" \
                --query "[?roleDefinitionName=='Key Vault Crypto Officer'].roleDefinitionName" \
                -o tsv 2>/dev/null || echo "")
            
            if [ -z "$current_user_crypto" ]; then
                print_status "Assigning Key Vault Crypto Officer role to current user for key creation..."
                if az role assignment create \
                    --assignee "${current_user}" \
                    --role "Key Vault Crypto Officer" \
                    --scope "${kv_scope}" \
                    --only-show-errors 2>/dev/null; then
                    print_success "Key Vault Crypto Officer role assigned to current user"
                else
                    print_warning "Failed to assign Key Vault Crypto Officer role (you may need to create keys manually)"
                fi
            else
                print_info "Current user already has Key Vault Crypto Officer role"
            fi
        else
            print_warning "Could not determine current user - you may need to assign roles manually"
            print_info "Manual command: az role assignment create --assignee '<your-email>' --role 'Key Vault Secrets Officer' --scope '${kv_scope}'"
        fi
    else
        # Set access policies for Service Principal (legacy method)
        print_status "Setting Key Vault access policies for Service Principal..."
    
    local policy_set=false
    
    # Approach 1: Try with SPN (Service Principal Name)
    if az keyvault set-policy \
        --name "${ACTUAL_KEYVAULT_NAME}" \
            --resource-group "${AZURE_RESOURCE_GROUP}" \
            --spn "${SERVICE_PRINCIPAL_CLIENT_ID}" \
        --secret-permissions get list \
        --only-show-errors; then
        print_success "Key Vault access policies configured for Service Principal (SPN method)"
        policy_set=true
    else
        print_warning "SPN method failed. Trying object ID method..."
        
        # Approach 2: Try to get object ID and use it
        local object_id=$(az ad sp show --id "${SERVICE_PRINCIPAL_CLIENT_ID}" --query "id" -o tsv 2>/dev/null || echo "")
        if [ -n "$object_id" ]; then
            if az keyvault set-policy \
                --name "${ACTUAL_KEYVAULT_NAME}" \
                --resource-group "${AZURE_RESOURCE_GROUP}" \
                --object-id "${object_id}" \
                --secret-permissions get list \
                --only-show-errors; then
                print_success "Key Vault access policies configured for Service Principal (Object ID method)"
                policy_set=true
            else
                print_warning "Object ID method also failed"
            fi
        else
            print_warning "Could not retrieve Service Principal object ID"
        fi
    fi
    
    if [ "$policy_set" = false ]; then
        print_error "Failed to set Key Vault access policies (authentication issue)"
        print_info "Please set access policies manually:"
        print_info "az keyvault set-policy --name '${ACTUAL_KEYVAULT_NAME}' --resource-group '${AZURE_RESOURCE_GROUP}' --spn '${SERVICE_PRINCIPAL_CLIENT_ID}' --secret-permissions get list"
        print_info "Or try with object ID:"
        print_info "az keyvault set-policy --name '${ACTUAL_KEYVAULT_NAME}' --resource-group '${AZURE_RESOURCE_GROUP}' --object-id '<OBJECT_ID>' --secret-permissions get list"
    fi
    fi
    
    # Create example secrets (matching what examples need)
    print_status "Creating example secrets for use with SecretProviderClass examples..."
    
    # Wait a moment for access policies to propagate
    print_status "Waiting for access policies to propagate..."
    sleep 5
    
    # Helper function to create a secret with retry
    create_keyvault_secret() {
        local secret_name=$1
        local secret_value=$2
        local retry_count=0
        local max_retries=2
        
        while [ $retry_count -lt $max_retries ]; do
            if az keyvault secret set \
                --vault-name "${ACTUAL_KEYVAULT_NAME}" \
                --name "${secret_name}" \
                --value "${secret_value}" \
                --only-show-errors 2>/dev/null; then
                return 0
            else
                retry_count=$((retry_count + 1))
                if [ $retry_count -lt $max_retries ]; then
                    sleep 2
                fi
            fi
        done
        
        # Try alternative method
        if echo "${secret_value}" | az keyvault secret set \
            --vault-name "${ACTUAL_KEYVAULT_NAME}" \
            --name "${secret_name}" \
            --file /dev/stdin \
            --only-show-errors 2>/dev/null; then
            return 0
        fi
        
        return 1
    }
    
    # Track which secrets were created successfully
    # Total breakdown: 1 (hello-world) + 2 (basic secrets) + 3 (ssl-cert cert+key + ssl-private-key) + 1 (shared) + 3 (rotating) = 10
    # Note: ssl-certificate creation counts as 2 because it creates both a certificate and an associated key named "ssl-certificate"
    #       ssl-private-key is a separate standalone key object
    local secrets_created=0
    local secrets_total=10
    
    # Secrets for web applications (hello-world-app)
    print_status "Creating secrets for hello-world web applications..."
    
    if create_keyvault_secret "hello-world-secret" "Hello from Azure Key Vault via Web Apps!"; then
        print_success "hello-world-secret created"
        secrets_created=$((secrets_created + 1))
    else
        print_warning "Failed to create hello-world-secret"
    fi
    
    # Secrets for basic-secret-sync and mixed-secrets-sync examples
    print_status "Creating secrets for basic-secret-sync and mixed-secrets-sync examples..."
    
    if create_keyvault_secret "database-password" "SecureDatabasePassword123!"; then
        print_success "database-password created"
        secrets_created=$((secrets_created + 1))
    else
        print_warning "Failed to create database-password"
    fi
    
    if create_keyvault_secret "api-key" "sk-1234567890abcdef"; then
        print_success "api-key created"
        secrets_created=$((secrets_created + 1))
    else
        print_warning "Failed to create api-key"
    fi
    
    # Additional secrets for mixed-secrets-sync example (certificates and keys)
    print_status "Creating certificate and key for mixed-secrets-sync example..."
    
    # Create a self-signed certificate in Key Vault (will also create the associated key)
    print_status "Creating self-signed SSL certificate..."
    if az keyvault certificate create \
        --vault-name "${ACTUAL_KEYVAULT_NAME}" \
        --name "ssl-certificate" \
        --policy "$(az keyvault certificate get-default-policy)" \
        --only-show-errors 2>/dev/null; then
        print_success "ssl-certificate created as certificate (includes private key)"
        secrets_created=$((secrets_created + 2))  # Count both cert and key
    else
        # Fallback: Check if it already exists
        if az keyvault certificate show --vault-name "${ACTUAL_KEYVAULT_NAME}" --name "ssl-certificate" &>/dev/null; then
            print_info "ssl-certificate already exists"
            secrets_created=$((secrets_created + 2))
        else
            print_warning "Failed to create ssl-certificate as certificate"
            print_info "Note: The mixed-secrets-sync example requires certificates and keys"
            print_info "You may need to create them manually or update the example to use secrets only"
        fi
    fi
    
    # Note: When a certificate is created in Key Vault, the private key is automatically stored as a key
    # The certificate name "ssl-certificate" will have an associated key with the same name
    
    # Create a separate key for the mixed-secrets-sync example
    # The example expects "ssl-private-key" as a separate key object
    print_status "Creating ssl-private-key for mixed-secrets-sync example..."
    if az keyvault key create \
        --vault-name "${ACTUAL_KEYVAULT_NAME}" \
        --name "ssl-private-key" \
        --kty RSA \
        --size 2048 \
        --only-show-errors 2>/dev/null; then
        print_success "ssl-private-key created"
        secrets_created=$((secrets_created + 1))
    else
        # Check if it already exists
        if az keyvault key show --vault-name "${ACTUAL_KEYVAULT_NAME}" --name "ssl-private-key" &>/dev/null; then
            print_info "ssl-private-key already exists"
            secrets_created=$((secrets_created + 1))
        else
            print_warning "Failed to create ssl-private-key"
            print_info "The mixed-secrets-sync example may not work without this key"
        fi
    fi
    
    
    if create_keyvault_secret "shared-readonly-config" "SharedConfigValue=readonly"; then
        print_success "shared-readonly-config created"
        secrets_created=$((secrets_created + 1))
    else
        print_warning "Failed to create shared-readonly-config"
    fi
    
    # Secrets for rotating-secrets and rotating-externalsecret examples
    print_status "Creating rotating secrets for rotation examples..."
    
    if create_keyvault_secret "rotating-database-password" "RotatingPassword123!v1"; then
        print_success "rotating-database-password created"
        secrets_created=$((secrets_created + 1))
    else
        print_warning "Failed to create rotating-database-password"
    fi
    
    if create_keyvault_secret "rotating-api-key" "rotating-api-key-v1"; then
        print_success "rotating-api-key created"
        secrets_created=$((secrets_created + 1))
    else
        print_warning "Failed to create rotating-api-key"
    fi
    
    if create_keyvault_secret "rotating-jwt-secret" "rotating-jwt-secret-value-v1"; then
        print_success "rotating-jwt-secret created"
        secrets_created=$((secrets_created + 1))
    else
        print_warning "Failed to create rotating-jwt-secret"
    fi
    
    # Summary of secret creation
    if [ "$secrets_created" -eq "$secrets_total" ]; then
        print_success "All secrets created successfully (${secrets_created}/${secrets_total})"
        print_info "Created web app secrets: hello-world-secret"
        print_info "Created example secrets: database-password, api-key, ssl-certificate, ssl-private-key"
        print_info "Created shared secret: shared-readonly-config"
        print_info "Created rotating secrets: rotating-database-password, rotating-api-key, rotating-jwt-secret"
    elif [ "$secrets_created" -gt 0 ]; then
        print_warning "Some secrets created successfully (${secrets_created}/${secrets_total}), others failed"
        print_info "You may need to create missing secrets manually or check Key Vault permissions"
    else
        print_warning "Failed to create secrets"
        print_info "Manual secret creation commands:"
        print_info "az keyvault secret set --vault-name '${ACTUAL_KEYVAULT_NAME}' --name 'hello-world-secret' --value 'Hello from Azure Key Vault via Web Apps!'"
        print_info "az keyvault secret set --vault-name '${ACTUAL_KEYVAULT_NAME}' --name 'database-password' --value 'SecureDatabasePassword123!'"
        print_info "az keyvault secret set --vault-name '${ACTUAL_KEYVAULT_NAME}' --name 'api-key' --value 'sk-1234567890abcdef'"
        print_info "az keyvault secret set --vault-name '${ACTUAL_KEYVAULT_NAME}' --name 'rotating-database-password' --value 'RotatingPassword123!v1'"
        print_info "az keyvault secret set --vault-name '${ACTUAL_KEYVAULT_NAME}' --name 'rotating-api-key' --value 'rotating-api-key-v1'"
        print_info "az keyvault secret set --vault-name '${ACTUAL_KEYVAULT_NAME}' --name 'rotating-jwt-secret' --value 'rotating-jwt-secret-value-v1'"
        print_info "az keyvault secret set --vault-name '${ACTUAL_KEYVAULT_NAME}' --name 'shared-readonly-config' --value 'SharedConfigValue=readonly'"
    fi
    
    print_success "Azure resources setup completed!"
}

# Validate Azure resources
validate_azure_resources() {
    print_header "Validating Azure Resources"
    
    local validation_passed=true
    
    # Set prefix for validation
    export AZURE_RESOURCE_PREFIX="${AZURE_RESOURCE_PREFIX:-aro-secrets-}"
    export ACTUAL_KEYVAULT_NAME="${AZURE_RESOURCE_PREFIX}${KEYVAULT_NAME}"
    export ACTUAL_SERVICE_PRINCIPAL_NAME="${AZURE_RESOURCE_PREFIX}${SERVICE_PRINCIPAL_NAME}"
    
    # Check Azure CLI authentication
    print_status "Checking Azure CLI authentication..."
    if ! az account show &> /dev/null; then
        print_error "Azure CLI not authenticated"
        validation_passed=false
    else
        print_success "Azure CLI authenticated"
        
        # Fetch and verify subscription
        CURRENT_SUB=$(az account show --query id -o tsv)
        CURRENT_TENANT=$(az account show --query tenantId -o tsv)
        print_info "Current subscription: ${CURRENT_SUB}"
        print_info "Current tenant: ${CURRENT_TENANT}"
    fi
    
    # Check subscription
    print_status "Checking Azure subscription..."
    CURRENT_SUB=$(az account show --query id -o tsv)
    if [ "${CURRENT_SUB}" = "${AZURE_SUBSCRIPTION_ID}" ]; then
        print_success "Correct subscription: ${AZURE_SUBSCRIPTION_ID}"
    else
        print_error "Wrong subscription. Expected: ${AZURE_SUBSCRIPTION_ID}, Current: ${CURRENT_SUB}"
        validation_passed=false
    fi
    
    # Check resource group
    print_status "Checking resource group..."
    if az group show --name "${AZURE_RESOURCE_GROUP}" &> /dev/null; then
        print_success "Resource group exists: ${AZURE_RESOURCE_GROUP}"
    else
        print_error "Resource group not found: ${AZURE_RESOURCE_GROUP}"
        validation_passed=false
    fi
    
    # Check Key Vault (fetch from Azure)
    print_status "Checking Key Vault..."
    if fetch_keyvault_info "${ACTUAL_KEYVAULT_NAME}" "${AZURE_RESOURCE_GROUP}"; then
        print_success "Key Vault exists: ${ACTUAL_KEYVAULT_NAME}"
        print_info "Key Vault URL: ${KEYVAULT_URL}"
    else
        print_error "Key Vault not found: ${ACTUAL_KEYVAULT_NAME}"
        validation_passed=false
    fi
    
    # Check Service Principal (fetch from Azure by name)
    print_status "Checking Service Principal..."
    FETCHED_SP_CLIENT_ID=$(fetch_service_principal_info "${ACTUAL_SERVICE_PRINCIPAL_NAME}")
    if [ -n "${FETCHED_SP_CLIENT_ID}" ]; then
        print_success "Service Principal found: ${FETCHED_SP_CLIENT_ID}"
        export SERVICE_PRINCIPAL_CLIENT_ID="${FETCHED_SP_CLIENT_ID}"
    elif [ -n "${SERVICE_PRINCIPAL_CLIENT_ID:-}" ] && az ad sp show --id "${SERVICE_PRINCIPAL_CLIENT_ID}" &> /dev/null; then
        print_success "Service Principal exists: ${SERVICE_PRINCIPAL_NAME}"
    else
        print_error "Service Principal not found: ${ACTUAL_SERVICE_PRINCIPAL_NAME}"
        print_info "Please verify the Service Principal exists or check Azure permissions"
        validation_passed=false
    fi
    
    # Test Key Vault access
    print_status "Testing Key Vault access..."
    # Try to access one of the secrets we create (database-password or hello-world-secret)
    if az keyvault secret show --vault-name "${ACTUAL_KEYVAULT_NAME}" --name "database-password" &> /dev/null || \
       az keyvault secret show --vault-name "${ACTUAL_KEYVAULT_NAME}" --name "hello-world-secret" &> /dev/null; then
        print_success "Key Vault access working"
    else
        print_warning "Cannot access Key Vault secrets (may be due to role propagation delay)"
        print_info "Note: Secrets were created successfully, but access test failed"
        print_info "This is usually a temporary propagation issue and should resolve in a few minutes"
        # Don't fail validation for this - secrets were created successfully
    fi
    
    if [ "$validation_passed" = true ]; then
        print_success "Azure resources validation passed!"
        return 0
    else
        print_error "Azure resources validation failed!"
        return 1
    fi
}

# Configure the Red Hat system operator (install if not present)
configure_operator() {
    print_header "Configuring Red Hat Secrets Store CSI Driver System Operator"
    
    # Check if the system operator is available
    print_status "Checking for Red Hat Secrets Store CSI Driver system operator..."
    CSV_NAME=$(timeout 10 oc get csv -n ${OPERATOR_NAMESPACE} 2>/dev/null | grep "secrets-store-csi-driver-operator" | awk '{print $1}' | head -1 || echo "")
    
    if [ -n "${CSV_NAME}" ]; then
        print_success "Red Hat Secrets Store CSI Driver system operator is available"
        
        # Check its status
        CSV_PHASE=$(oc get csv ${CSV_NAME} -n ${OPERATOR_NAMESPACE} -o jsonpath='{.status.phase}')
        
        if [ "${CSV_PHASE}" = "Succeeded" ]; then
            print_success "System operator is ready and running"
        else
            print_warning "System operator is in phase: ${CSV_PHASE}"
            print_status "Waiting for system operator to be ready..."
            oc wait --for=jsonpath='{.status.phase}'=Succeeded csv/${CSV_NAME} -n ${OPERATOR_NAMESPACE} --timeout=300s || true
        fi
    else
        print_warning "Red Hat Secrets Store CSI Driver system operator not found in ${OPERATOR_NAMESPACE}"
        print_status "Attempting to install from Operator catalog..."
        
        # Check if operator is available in catalog
        if oc get packagemanifest secrets-store-csi-driver-operator -n openshift-marketplace &>/dev/null; then
            print_success "Operator found in catalog, proceeding with installation..."
            
            # Ensure namespace exists
            oc get namespace ${OPERATOR_NAMESPACE} &>/dev/null || oc create namespace ${OPERATOR_NAMESPACE}
            
            # Create OperatorGroup for cluster-wide installation
            # Note: Manifest uses upgradeStrategy: Default and no targetNamespaces (cluster-wide)
            print_status "Creating OperatorGroup for cluster-wide installation..."
            EXISTING_OG=$(oc get operatorgroup -n ${OPERATOR_NAMESPACE} -o name 2>/dev/null | head -1)
            
            if [ -z "${EXISTING_OG}" ]; then
                # No OperatorGroup exists, create from manifest (creates both OperatorGroup and Subscription)
                print_status "Creating OperatorGroup and Subscription from manifest..."
                # Manifest is now hardcoded, no need for envsubst
                oc apply -f manifests/secrets-store-csi-driver/install.yaml
                print_success "OperatorGroup and Subscription created from manifest"
            else
                # Check if existing OperatorGroup is configured correctly
                OG_SPEC=$(oc get ${EXISTING_OG} -n ${OPERATOR_NAMESPACE} -o jsonpath='{.spec}' 2>/dev/null)
                if [ -n "${OG_SPEC}" ] && echo "${OG_SPEC}" | grep -q "targetNamespaces"; then
                    print_warning "Existing OperatorGroup is configured for OwnNamespace mode, which is not supported"
                    print_status "Deleting and recreating OperatorGroup with cluster-wide configuration..."
                    oc delete ${EXISTING_OG} -n ${OPERATOR_NAMESPACE}
                    sleep 2
                    # Manifest is now hardcoded, no need for envsubst
                    oc apply -f manifests/secrets-store-csi-driver/install.yaml
                    print_success "OperatorGroup recreated for cluster-wide installation"
                else
                    print_info "OperatorGroup already exists and is correctly configured"
                fi
                
                # Create Subscription if it doesn't exist
                print_status "Checking Subscription..."
                if ! oc get subscription secrets-store-csi-driver-operator -n ${OPERATOR_NAMESPACE} &>/dev/null; then
                    # Manifest is now hardcoded, no need for envsubst
                    oc apply -f manifests/secrets-store-csi-driver/install.yaml
                    print_success "Subscription created"
                else
                    print_info "Subscription already exists"
                fi
            fi
            
            # Wait for CSV to appear
            print_status "Waiting for ClusterServiceVersion to be created..."
            local wait_count=0
            while [ $wait_count -lt 30 ]; do
                CSV_NAME=$(timeout 10 oc get csv -n ${OPERATOR_NAMESPACE} 2>/dev/null | grep "secrets-store-csi-driver-operator" | awk '{print $1}' | head -1 || echo "")
                if [ -n "${CSV_NAME}" ]; then
                    break
                fi
                sleep 2
                wait_count=$((wait_count + 1))
            done
            
            if [ -z "${CSV_NAME}" ]; then
                print_error "ClusterServiceVersion not created after 60 seconds"
                print_info "Please check the Subscription status manually"
                exit 1
            fi
            
            print_success "ClusterServiceVersion found: ${CSV_NAME}"
            
            # Wait for CSV to be in Succeeded phase
    print_status "Waiting for operator to be ready..."
            oc wait --for=jsonpath='{.status.phase}'=Succeeded csv/${CSV_NAME} -n ${OPERATOR_NAMESPACE} --timeout=600s || {
                print_error "Operator did not reach Succeeded phase within 10 minutes"
                print_info "Current CSV status:"
                oc get csv ${CSV_NAME} -n ${OPERATOR_NAMESPACE} -o yaml | grep -A 5 "status:"
                exit 1
            }
            
            print_success "Operator installed and ready!"
        else
            print_error "Secrets Store CSI Driver operator not found in Operator catalog"
            print_info "Please check your OpenShift installation or contact your cluster administrator"
            exit 1
        fi
    fi
    
    # Install ClusterCSIDriver after operator is ready (required for complete installation)
    # Note: We can install ClusterCSIDriver as soon as the CRD is available,
    # even if the CSV is still in Pending/Installing phase
    print_status "Preparing to install ClusterCSIDriver..."
    
    # Check if ClusterCSIDriver already exists
    if oc get clustercsidriver secrets-store.csi.k8s.io &>/dev/null 2>&1; then
        print_info "ClusterCSIDriver already exists, skipping installation"
        local driver_state=$(oc get clustercsidriver secrets-store.csi.k8s.io -o jsonpath='{.spec.managementState}' 2>/dev/null || echo "Unknown")
        print_info "ClusterCSIDriver managementState: ${driver_state}"
        return 0
    fi
    
    # Check if the CRD is available (this is what we really need, not necessarily the CSV being Succeeded)
    print_status "Checking if ClusterCSIDriver CRD is available..."
    local crd_wait_count=0
    local crd_available=false
    
    while [ $crd_wait_count -lt 30 ]; do
        # Check if CRD exists
        if oc get crd clustercsidrivers.operator.openshift.io &>/dev/null 2>&1; then
            crd_available=true
            break
        fi
        # Also check API resources as fallback
        if oc api-resources --api-group=operator.openshift.io 2>/dev/null | grep -q "clustercsidrivers"; then
            crd_available=true
            break
        fi
        sleep 2
        crd_wait_count=$((crd_wait_count + 1))
    done
    
    if [ "$crd_available" = false ]; then
        # Check CSV status for informational purposes
        CSV_NAME=$(timeout 10 oc get csv -n ${OPERATOR_NAMESPACE} 2>/dev/null | grep "secrets-store-csi-driver-operator" | awk '{print $1}' | head -1 || echo "")
        if [ -n "${CSV_NAME}" ]; then
            CSV_PHASE=$(oc get csv ${CSV_NAME} -n ${OPERATOR_NAMESPACE} -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
            print_warning "ClusterCSIDriver CRD not available after 60 seconds (CSV phase: ${CSV_PHASE})"
        else
            print_warning "ClusterCSIDriver CRD not available after 60 seconds"
        fi
        print_info "This may be normal - the operator may not have installed the CRD yet"
        print_info "You may need to create the ClusterCSIDriver resource manually later"
        print_info "Or wait for the operator to be fully ready and run installation again"
        return 0
    fi
    
    print_status "ClusterCSIDriver CRD is available, installing ClusterCSIDriver..."
    
    # Apply the ClusterCSIDriver resource
    if oc apply -f manifests/secrets-store-csi-driver/clustercsidriver.yaml 2>&1; then
        # Wait a moment for it to be processed
        sleep 2
        
        # Verify ClusterCSIDriver was created
        if oc get clustercsidriver secrets-store.csi.k8s.io &>/dev/null 2>&1; then
            print_success "ClusterCSIDriver installed successfully"
            
            # Verify it's in the correct state
            local driver_state=$(oc get clustercsidriver secrets-store.csi.k8s.io -o jsonpath='{.spec.managementState}' 2>/dev/null || echo "Unknown")
            print_info "ClusterCSIDriver managementState: ${driver_state}"
            return 0
        else
            print_warning "ClusterCSIDriver not found after application"
            print_info "Please verify manually: oc get clustercsidriver secrets-store.csi.k8s.io"
            return 0  # Don't fail - it might be processed asynchronously
        fi
    else
        print_error "Failed to apply ClusterCSIDriver resource"
        print_info "Error details logged above"
        return 1
    fi
    
    # Create our test namespace
    print_status "Creating test namespace..."
    envsubst < manifests/test/namespace.yaml | oc apply -f -
    
            # Create ServiceAccount for our applications
            print_status "Creating ServiceAccount for applications..."
            print_status "Creating ServiceAccount for Service Principal..."
        oc create serviceaccount ${SERVICE_ACCOUNT_NAME} -n ${NAMESPACE} --dry-run=client -o yaml | oc apply -f -
    
    # Create RBAC for our applications
    print_status "Creating RBAC for applications..."
    envsubst < manifests/test/service-principal-secret.yaml | oc apply -f -
    
    print_success "Red Hat Secrets Store CSI Driver system operator configuration completed"
}

# Install External Secrets Operator
install_external_secrets_operator() {
    print_header "Installing External Secrets Operator"
    
    # Check if External Secrets Operator is already installed
    if oc get csv -n external-secrets-operator | grep -q "external-secrets-operator" && oc get csv -n external-secrets-operator | grep -q "Succeeded"; then
        print_info "External Secrets Operator is already installed in external-secrets-operator namespace"
        return 0
    fi
    
    print_status "Installing External Secrets Operator..."
    oc apply -f manifests/external-secrets-operator/install.yaml
    
    print_status "Waiting for External Secrets Operator to be ready..."
    # Wait for CSV to be in Succeeded phase - find the actual CSV name
    local wait_count=0
    local eso_csv=""
    while [ $wait_count -lt 30 ]; do
        eso_csv=$(oc get csv -n external-secrets-operator 2>/dev/null | grep "external-secrets-operator" | awk '{print $1}' | head -1)
        if [ -n "${eso_csv}" ]; then
            break
        fi
        sleep 2
        wait_count=$((wait_count + 1))
    done
    
    if [ -z "${eso_csv}" ]; then
        print_error "External Secrets Operator CSV not found after 60 seconds"
        print_info "Please check the Subscription status manually"
        exit 1
    fi
    
    oc wait --for=jsonpath='{.status.phase}'=Succeeded csv/${eso_csv} -n external-secrets-operator --timeout=600s || {
        print_error "External Secrets Operator did not reach Succeeded phase within 10 minutes"
        print_info "Current CSV status:"
        oc get csv ${eso_csv} -n external-secrets-operator -o yaml | grep -A 5 "status:" || true
        exit 1
    }
    
    # Wait for the CRD to be available before creating the ExternalSecrets resource
    print_status "Waiting for ExternalSecrets CRD to be available..."
    local crd_wait_count=0
    while [ $crd_wait_count -lt 30 ]; do
        if oc api-resources | grep -E "externalsecrets.*operator\.openshift\.io"; then
            break
        fi
        sleep 2
        crd_wait_count=$((crd_wait_count + 1))
    done
    
    if oc api-resources | grep -E "externalsecrets.*operator\.openshift\.io"; then
        print_status "Creating External Secrets configuration..."
        oc apply -f manifests/external-secrets-operator/externalsecrets.yaml
        
        # Wait for operator controller deployments to be ready
        print_status "Waiting for External Secrets Operator controller pods to be ready..."
        local controller_wait_count=0
        local controllers_ready=false
        
        while [ $controller_wait_count -lt 60 ]; do
            # Check if the main controller deployment exists and is ready
            local main_deployment=$(oc get deployment external-secrets -n external-secrets -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
            local main_replicas=$(oc get deployment external-secrets -n external-secrets -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "0")
            
            if [ "$main_deployment" = "$main_replicas" ] && [ "$main_replicas" != "0" ]; then
                # Also check webhook deployment
                local webhook_deployment=$(oc get deployment external-secrets-webhook -n external-secrets -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
                local webhook_replicas=$(oc get deployment external-secrets-webhook -n external-secrets -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "0")
                
                if [ "$webhook_deployment" = "$webhook_replicas" ] && [ "$webhook_replicas" != "0" ]; then
                    controllers_ready=true
                    break
                fi
            fi
            
            sleep 2
            controller_wait_count=$((controller_wait_count + 1))
        done
        
        if [ "$controllers_ready" = true ]; then
            print_success "External Secrets Operator controller pods are ready"
        else
            print_warning "External Secrets Operator controller pods not fully ready after 2 minutes"
            print_info "This is normal - pods may still be starting up"
            print_info "You can check status with: oc get pods -n external-secrets"
        fi
    else
        print_warning "ExternalSecrets CRD not available after 60 seconds, skipping configuration"
        print_info "You may need to create the ExternalSecrets resource manually later"
    fi
    
    print_success "External Secrets Operator installed successfully!"
}

# Install Azure provider
# Based on official OpenShift documentation: https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/nodes/working-with-pods#secrets-store-azure_nodes-pods-secrets-store
install_azure_provider() {
    print_header "Installing Azure Key Vault Provider"
    
    print_status "Installing Azure provider using official OpenShift method..."
    
    # Check if Azure provider is already installed
    if oc get daemonset csi-secrets-store-provider-azure -n ${NAMESPACE} &>/dev/null; then
        print_status "Azure provider already installed, skipping installation..."
    else
        # Apply the Azure provider manifest (ServiceAccount, RBAC, DaemonSet)
        print_status "Applying Azure provider manifest..."
        oc apply -f manifests/secrets-store-csi-driver/azure-provider.yaml
        
        # Grant privileged SCC to Azure provider ServiceAccount (required for hostPath volumes)
    print_status "Granting privileged SCC to Azure provider ServiceAccount..."
        oc adm policy add-scc-to-user privileged -z csi-secrets-store-provider-azure -n ${NAMESPACE} || {
            print_warning "Failed to grant privileged SCC - Azure provider may not function correctly"
            print_info "You may need to grant this manually:"
            print_info "oc adm policy add-scc-to-user privileged -z csi-secrets-store-provider-azure -n ${NAMESPACE}"
        }
        
        # Wait for DaemonSet pods to be ready
    print_status "Waiting for Azure provider pods to be ready..."
        oc rollout status daemonset/csi-secrets-store-provider-azure -n ${NAMESPACE} --timeout=300s || {
            print_warning "DaemonSet rollout did not complete within timeout"
            print_info "Check pod status with: oc get pods -n ${NAMESPACE} -l app=csi-secrets-store-provider-azure"
        }
        
        # Verify pods are running
        local ready_pods=$(oc get pods -n ${NAMESPACE} -l app=csi-secrets-store-provider-azure --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
        local expected_pods=$(oc get nodes --no-headers 2>/dev/null | wc -l)
        
        if [ "$ready_pods" -gt 0 ]; then
            print_success "Azure provider pods running (${ready_pods}/${expected_pods} expected)"
        else
            print_warning "No Azure provider pods running yet"
            print_info "Pods should start shortly. Check status with: oc get pods -n ${NAMESPACE} -l app=csi-secrets-store-provider-azure"
        fi
    fi
    
    print_success "Azure Key Vault Provider installation completed"
}


# Validate installation
validate_installation() {
    print_header "Validating Installation"
    
    local validation_passed=true
    
    # Detect what's actually installed rather than relying on installation flags
    local sscsi_installed=false
    local eso_installed=false
    
    # Check if SSCSI is installed
    if oc get csv -n ${OPERATOR_NAMESPACE} 2>/dev/null | grep -q "secrets-store-csi-driver-operator"; then
        sscsi_installed=true
    fi
    
    # Check if ESO is installed
    if oc get csv -n external-secrets-operator 2>/dev/null | grep -E "external-secrets-operator"; then
        eso_installed=true
    fi
    
    # Check SSCSI operator CSV status (only if SSCSI is actually installed)
    if [[ "$sscsi_installed" == "true" ]]; then
        print_status "Checking Secrets Store CSI Driver operator..."
        CSV_NAME=$(timeout 10 oc get csv -n ${OPERATOR_NAMESPACE} 2>/dev/null | grep "secrets-store-csi-driver-operator" | awk '{print $1}' | head -1 || echo "")
        if [ -n "${CSV_NAME}" ]; then
            CSV_PHASE=$(oc get csv ${CSV_NAME} -n ${OPERATOR_NAMESPACE} -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
            if [ "${CSV_PHASE}" = "Succeeded" ]; then
                print_success "Secrets Store CSI Driver operator is ready (${CSV_NAME})"
            else
                print_warning "Secrets Store CSI Driver operator is in phase: ${CSV_PHASE}"
                validation_passed=false
            fi
        else
            print_error "Secrets Store CSI Driver operator not found"
            validation_passed=false
        fi
    fi
    
    # Check ClusterCSIDriver (only if SSCSI is actually installed)
    if [[ "$sscsi_installed" == "true" ]]; then
        print_status "Checking ClusterCSIDriver..."
        if oc get clustercsidriver secrets-store.csi.k8s.io &>/dev/null; then
            DRIVER_STATE=$(oc get clustercsidriver secrets-store.csi.k8s.io -o jsonpath='{.spec.managementState}' 2>/dev/null || echo "Unknown")
            print_success "ClusterCSIDriver found (managementState: ${DRIVER_STATE})"
        else
            print_error "ClusterCSIDriver not found"
            validation_passed=false
        fi
    fi
    
    # Check CSIDriver (only if SSCSI is actually installed)
    if [[ "$sscsi_installed" == "true" ]]; then
        print_status "Checking CSIDriver..."
        if oc get csidriver secrets-store.csi.k8s.io &>/dev/null; then
            print_success "CSIDriver found"
        else
            # CSIDriver is created automatically by the operator, so this is a warning, not an error
            # It may take some time for the operator to create it after ClusterCSIDriver is set to Managed
            print_warning "CSIDriver not found (may be created automatically by operator)"
            if oc get clustercsidriver secrets-store.csi.k8s.io -o jsonpath='{.spec.managementState}' 2>/dev/null | grep -q "Managed"; then
                print_info "ClusterCSIDriver is in Managed state - CSIDriver should be created automatically"
                # Don't fail validation for this - it's informational
            fi
        fi
    fi
    
    # Check Azure provider pods (only if SSCSI is actually installed)
    if [[ "$sscsi_installed" == "true" ]]; then
        print_status "Checking Azure provider pods..."
        local provider_pods=$(oc get pods -n ${NAMESPACE} -l app=csi-secrets-store-provider-azure --no-headers 2>/dev/null | wc -l | tr -d ' ')
        local provider_ready=$(oc get pods -n ${NAMESPACE} -l app=csi-secrets-store-provider-azure --no-headers 2>/dev/null | grep Running | wc -l | tr -d ' ')
        if [ "${provider_pods}" -gt 0 ]; then
        oc get pods -n ${NAMESPACE} -l app=csi-secrets-store-provider-azure
            if [ "${provider_ready}" -eq "${provider_pods}" ]; then
                print_success "Azure provider pods running (${provider_ready}/${provider_pods})"
            else
                print_warning "Azure provider pods: ${provider_ready}/${provider_pods} ready"
                validation_passed=false
            fi
        else
            print_error "Azure provider pods not found"
            validation_passed=false
        fi
    fi
    
    
    # Check ESO if actually installed
    if [[ "$eso_installed" == "true" ]]; then
        print_status "Checking External Secrets Operator..."
        ESO_CSV=$(oc get csv -n external-secrets-operator 2>/dev/null | grep -E "openshift-external-secrets-operator|external-secrets-operator" | awk '{print $1}' | head -1)
        if [ -n "${ESO_CSV}" ]; then
            ESO_PHASE=$(oc get csv ${ESO_CSV} -n external-secrets-operator -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
            if [ "${ESO_PHASE}" = "Succeeded" ]; then
                print_success "External Secrets Operator is ready (${ESO_CSV})"
            else
                print_warning "External Secrets Operator is in phase: ${ESO_PHASE}"
            fi
        else
            print_error "External Secrets Operator CSV not found"
            validation_passed=false
        fi
    fi
    
    if [ "$validation_passed" = true ]; then
    print_success "Installation validation completed!"
        return 0
    else
        print_error "Installation validation found issues!"
        return 1
    fi
}

# Show post-installation information
show_post_install_info() {
    print_header "Installation Complete!"
    
    if [[ "$INSTALL_SSCSI" == "true" ]]; then
        echo -e "${GREEN}✅ Red Hat Secrets Store CSI Driver Operator installed${NC}"
        echo -e "${GREEN}✅ Azure Key Vault Provider installed${NC}"
    fi
    if [[ "$INSTALL_ESO" == "true" ]]; then
        echo -e "${GREEN}✅ External Secrets Operator installed${NC}"
    fi
    echo ""
    echo -e "${CYAN}Next Steps:${NC}"
    echo "1. Create test resources: ./bin/examples apply basic-secret-sync"
    echo "2. Deploy webapps: ./hello-world-app/deploy.sh deploy <app-type>"
    echo "3. Run examples: ./bin/examples list"
    echo ""
    echo -e "${CYAN}Useful Commands:${NC}"
    echo "  oc get pods -n ${NAMESPACE}"
    echo "  oc logs -n ${NAMESPACE} -l app=csi-secrets-store-provider-azure"
    if [[ "$INSTALL_ESO" == "true" ]]; then
        echo "  oc get pods -n external-secrets"
    fi
}

# Force delete resources with finalizers
force_delete_with_finalizers() {
    local resource_type="$1"
    local namespace="$2"
    local label_selector="$3"
    
    local resources=""
    if [ -n "$namespace" ]; then
        resources=$(oc get "$resource_type" -n "$namespace" -l "$label_selector" --no-headers 2>/dev/null | awk '{print $1}' || true)
    else
        resources=$(oc get "$resource_type" -l "$label_selector" --no-headers 2>/dev/null | awk '{print $1}' || true)
    fi
    
    [ -z "$resources" ] && return 0
    
    echo "$resources" | while read -r resource; do
        [ -z "$resource" ] && continue
        print_status "Force deleting $resource_type: $resource"
        if [ -n "$namespace" ]; then
            oc patch "$resource_type/$resource" -n "$namespace" --type='merge' -p='{"metadata":{"finalizers":[]}}' 2>/dev/null || true
            oc delete "$resource_type/$resource" -n "$namespace" --force --grace-period=0 --ignore-not-found=true 2>/dev/null || true
        else
            oc patch "$resource_type/$resource" --type='merge' -p='{"metadata":{"finalizers":[]}}' 2>/dev/null || true
            oc delete "$resource_type/$resource" --force --grace-period=0 --ignore-not-found=true 2>/dev/null || true
        fi
    done
}

# Delete resource with finalizer handling (moved outside function for reuse)
delete_with_finalizer_cleanup() {
    local resource_type="$1"
    local resource_name="$2"
    
    if ! oc get "$resource_type" "$resource_name" &>/dev/null; then
        return 0
    fi
    
    print_status "Deleting ${resource_type} ${resource_name}..."
    timeout 10 oc delete "$resource_type" "$resource_name" --ignore-not-found=true --request-timeout=5s &>/dev/null || true
    
    if oc get "$resource_type" "$resource_name" &>/dev/null 2>&1; then
        print_status "Removing finalizers from ${resource_type} ${resource_name}..."
        timeout 5 oc patch "$resource_type" "$resource_name" --type='merge' -p='{"metadata":{"finalizers":[]}}' --request-timeout=3s 2>/dev/null || true
        
        if [ "$force_flag" = "--force" ]; then
            timeout 10 oc delete "$resource_type" "$resource_name" --ignore-not-found=true --force --grace-period=0 --request-timeout=5s &>/dev/null || true
        fi
        
        if oc get "$resource_type" "$resource_name" &>/dev/null 2>&1 && [ "$resource_type" = "clustercsidriver" ]; then
            print_warning "${resource_type} ${resource_name} may still exist - operator may be managing it"
        fi
    fi
}

# Delete all custom resources for a CRD before deleting the CRD itself
delete_crd_resources() {
    local crd_name="$1"
    local crd_kind=$(oc get crd "$crd_name" -o jsonpath='{.spec.names.kind}' --request-timeout=10s 2>/dev/null || echo "")
    
    if [ -z "$crd_kind" ]; then
        print_warning "Could not determine kind for CRD: $crd_name (may already be deleted)"
        return 0  # Not an error, CRD might not exist
    fi
    
    print_status "Deleting all $crd_kind resources..."
    
    # Try to delete cluster-scoped resources first (faster, no namespace needed)
    local cluster_resources=$(timeout 15 oc get "$crd_kind" --no-headers --request-timeout=15s 2>/dev/null | awk '{print $1}' || true)
    if [ -n "$cluster_resources" ]; then
        echo "$cluster_resources" | while read -r resource; do
            if [ -n "$resource" ]; then
                print_status "Deleting cluster-scoped $crd_kind/$resource"
                timeout 10 oc delete "$crd_kind/$resource" --ignore-not-found=true --force --grace-period=0 --request-timeout=10s 2>/dev/null || true
            fi
        done
    fi
    
    # Try to delete from known namespaces only (much faster than all namespaces)
    local known_ns=("external-secrets-operator" "hello-world-apps")
    for ns in "${known_ns[@]}"; do
        # Check if namespace exists
        if ! oc get namespace "$ns" &>/dev/null; then
            continue
        fi
        
        # Get resources with timeout
        local resources=$(timeout 15 oc get "$crd_kind" -n "$ns" --no-headers --request-timeout=15s 2>/dev/null | awk '{print $1}' || true)
        if [ -n "$resources" ]; then
            echo "$resources" | while read -r resource; do
                if [ -n "$resource" ]; then
                    print_status "Deleting $crd_kind/$resource from namespace $ns"
                    timeout 10 oc delete "$crd_kind/$resource" -n "$ns" --ignore-not-found=true --force --grace-period=0 --request-timeout=10s 2>/dev/null || true
                fi
            done
        fi
    done
    
    # Wait a moment for resources to be deleted
    sleep 1
    
    print_info "Finished attempting to delete resources for CRD: $crd_name"
}

# Force delete a CRD with finalizer removal
force_delete_crd() {
    local crd_name="$1"
    local wait_timeout="${2:-10}"  # Reduced from 30 to 10 seconds
    
    if ! timeout 5 oc get crd "$crd_name" --request-timeout=5s &>/dev/null; then
        return 0  # CRD doesn't exist, nothing to do
    fi
    
    print_status "Force deleting CRD: $crd_name"
    
    # First, delete all custom resources that use this CRD
    delete_crd_resources "$crd_name"
    
    # Try normal deletion first (with timeout wrapper)
    timeout 15 oc delete crd "$crd_name" --ignore-not-found=true --request-timeout=10s 2>/dev/null || true
    
    # Wait a moment and check if it's gone
    sleep 2
    
    if ! timeout 5 oc get crd "$crd_name" --request-timeout=5s &>/dev/null; then
        print_success "CRD $crd_name deleted successfully"
        return 0
    fi
    
    # CRD is still there, force delete with finalizer removal
    print_warning "CRD $crd_name is stuck, removing finalizers..."
    
    # Remove finalizers from CRD (patch doesn't support --ignore-not-found)
    timeout 10 oc patch crd "$crd_name" --type='merge' -p='{"metadata":{"finalizers":[]}}' --request-timeout=10s 2>/dev/null || true
    
    # Force delete (with timeout)
    timeout 15 oc delete crd "$crd_name" --ignore-not-found=true --force --grace-period=0 --request-timeout=10s 2>/dev/null || true
    
    # Wait and check again (with timeout on each check)
    local wait_count=0
    while [ $wait_count -lt $wait_timeout ]; do
        if ! timeout 5 oc get crd "$crd_name" --request-timeout=5s &>/dev/null; then
            print_success "CRD $crd_name force deleted successfully"
            return 0
        fi
        sleep 1
        ((wait_count++))
    done
    
    # If still stuck, try one more aggressive approach
    if timeout 5 oc get crd "$crd_name" --request-timeout=5s &>/dev/null; then
        print_warning "CRD $crd_name still exists after force deletion"
        print_info "Attempting final aggressive cleanup..."
        
        # Try direct API call to remove finalizers (with timeouts)
        timeout 10 oc get crd "$crd_name" -o json --request-timeout=10s 2>/dev/null | timeout 5 jq 'del(.metadata.finalizers)' 2>/dev/null | timeout 15 oc replace -f - --request-timeout=10s 2>/dev/null || true
        timeout 15 oc delete crd "$crd_name" --ignore-not-found=true --force --grace-period=0 --request-timeout=10s 2>/dev/null || true
        
        sleep 2
        if ! timeout 5 oc get crd "$crd_name" --request-timeout=5s &>/dev/null; then
            print_success "CRD $crd_name deleted after aggressive cleanup"
            return 0
        else
            print_error "CRD $crd_name could not be deleted. You may need to delete it manually."
            print_info "Manual cleanup: oc patch crd $crd_name -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge"
            return 1
        fi
    fi
}

# Force delete namespace with finalizers
force_delete_namespace() {
    local namespace="$1"
    
    if [ -z "$namespace" ]; then
        return 0
    fi
    
    print_status "Checking if namespace '$namespace' is stuck with finalizers..."
    
    # Check if namespace exists and is stuck
    if oc get namespace "$namespace" &>/dev/null; then
        local phase=$(oc get namespace "$namespace" -o jsonpath='{.status.phase}' 2>/dev/null || echo "")
        if [ "$phase" = "Terminating" ]; then
            print_warning "Namespace '$namespace' is stuck in Terminating state. Force deleting..."
            
            # Remove finalizers and force delete
            oc patch namespace "$namespace" --type='merge' -p='{"metadata":{"finalizers":[]}}' --ignore-not-found=true
            oc delete namespace "$namespace" --force --grace-period=0 --ignore-not-found=true
            
            # Wait a moment and check if it's gone
            sleep 2
            if oc get namespace "$namespace" &>/dev/null; then
                print_error "Namespace '$namespace' still exists after force deletion"
            else
                print_success "Namespace '$namespace' successfully force deleted"
            fi
        fi
    fi
}

# Clean up Kubernetes resources
cleanup_kubernetes() {
    local force_flag="${1:-}"
    local operator_filter="${2:-}"
    
    print_header "Cleaning Up Kubernetes Resources"
    
    if [ "$force_flag" = "--force" ]; then
        print_warning "Force cleanup mode enabled - will aggressively remove finalizers and force delete resources"
    fi
    
    if [ -n "$operator_filter" ]; then
        print_info "Filtering cleanup to operator: $operator_filter"
    fi
    
    # Note: Hello World webapps cleanup is skipped - use 'cleanup all' if you want to remove those
    
    # Progress tracking
    local total_steps=12
    local current_step=0
    
    print_progress() {
        current_step=$((current_step + 1))
        print_status "Step $current_step/$total_steps: $1"
    }
    
    # Progress bar for CSV deletion
    show_csv_progress() {
        local current="$1"
        local total="$2"
        local csv_name="$3"
        local width=50
        local percentage=$((current * 100 / total))
        local filled=$((current * width / total))
        local empty=$((width - filled))
        
        printf "\r\033[K["
        printf "%*s" $filled | tr ' ' '='
        printf "%*s" $empty | tr ' ' ' '
        printf "] %d%% (%d/%d) %s" $percentage $current $total "$csv_name"
    }
    
    
    # Clean up Azure provider (only for SSCSI or if no filter)
    if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
        print_progress "Cleaning up Azure provider..."
        
        # Delete DaemonSet first so pods don't get recreated
        oc delete daemonset csi-secrets-store-provider-azure -n ${NAMESPACE} --ignore-not-found=true
        
        # Run parallel cleanup for Azure provider resources
        {
            oc delete pod -n ${NAMESPACE} -l app=csi-secrets-store-provider-azure --ignore-not-found=true
        } &
        
        {
            oc delete serviceaccount csi-secrets-store-provider-azure -n ${NAMESPACE} --ignore-not-found=true
        } &
        
        {
            oc delete clusterrole csi-secrets-store-provider-azure-cluster-role --ignore-not-found=true
            oc delete clusterrolebinding csi-secrets-store-provider-azure-cluster-rolebinding --ignore-not-found=true
        } &
        
        # Wait for parallel operations to complete
        wait
        
        # Remove privileged SCC (optional - may fail if used by other resources)
        oc adm policy remove-scc-from-user privileged -z csi-secrets-store-provider-azure -n ${NAMESPACE} 2>/dev/null || true
    fi
    
    # Clean up running pods created by operators
    print_progress "Cleaning up operator-managed pods..."
    
    # Clean up SSCSI driver pods (only if no filter or filter is sscsi)
    if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
        # Clean up SSCSI driver pods (these are managed by Red Hat system operator DaemonSets)
        # Note: These pods will be recreated by the system operator unless we scale down or delete the DaemonSets
        print_status "Cleaning up SSCSI driver pods and their controllers..."
        
        # Delete SSCSI DaemonSets first (correct dependency order)
        print_status "Deleting SSCSI DaemonSets..."
        {
            oc delete daemonset secrets-store-csi-driver-node -n ${NAMESPACE} --ignore-not-found=true
        } &
        
        {
            oc delete daemonset -n ${NAMESPACE} -l app=secrets-store-csi-driver --ignore-not-found=true
            oc delete daemonset -n ${NAMESPACE} -l app=secrets-store-csi-driver-node --ignore-not-found=true
        } &
        
        # Wait for DaemonSet deletions to complete
        wait
        
        # Then delete the actual pods
        if [ "$force_flag" = "--force" ]; then
            print_status "Force deleting SSCSI driver pods..."
            {
                oc delete pod -n ${NAMESPACE} -l app=secrets-store-csi-driver --ignore-not-found=true --force --grace-period=0
            } &
            {
                oc delete pod -n ${NAMESPACE} -l app=secrets-store-csi-driver-node --ignore-not-found=true --force --grace-period=0
            } &
        else
            print_status "Deleting SSCSI driver pods..."
            {
                oc delete pod -n ${NAMESPACE} -l app=secrets-store-csi-driver --ignore-not-found=true
            } &
            {
                oc delete pod -n ${NAMESPACE} -l app=secrets-store-csi-driver-node --ignore-not-found=true
            } &
        fi
        
        # Wait for pod deletions to complete
        wait
    fi
    
    # Clean up ESO (only if no filter or filter is eso)
    # Following official Red Hat ESO deletion procedure for reliability
    if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
        print_progress "Cleaning up External Secrets Operator (using official procedure)..."
        
        local eso_deployment_namespace="external-secrets"
        
        # Step 1: Delete deployments using official label selector
        print_status "Step 1: Deleting ESO deployments in external-secrets namespace..."
        oc delete deployment -n "$eso_deployment_namespace" -l app=external-secrets --ignore-not-found=true || true
        
        # Wait a moment for deployments to terminate
        sleep 2
    fi
    
    # Note: We don't clean up the Red Hat system operator as it's part of OpenShift
    if [ -z "$operator_filter" ]; then
        print_status "Skipping Red Hat system operator cleanup (it's part of OpenShift)..."
    fi
    
    # Clean up CSIDriver and ClusterCSIDriver resources (only for SSCSI)
    if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
        print_progress "Cleaning up CSIDriver and ClusterCSIDriver resources..."
        
        # Delete CSIDriver first (it's typically managed by ClusterCSIDriver)
        print_status "Deleting CSIDriver..."
        delete_with_finalizer_cleanup "csidriver" "secrets-store.csi.k8s.io"
        
        # Then delete ClusterCSIDriver (this will stop the operator from recreating CSIDriver)
        if oc get clustercsidriver secrets-store.csi.k8s.io &>/dev/null 2>&1; then
            print_status "Deleting ClusterCSIDriver..."
            oc delete clustercsidriver secrets-store.csi.k8s.io --ignore-not-found=true --timeout=30s || {
                print_warning "ClusterCSIDriver deletion timed out, attempting force delete..."
                oc delete clustercsidriver secrets-store.csi.k8s.io --ignore-not-found=true --force --grace-period=0 || true
                force_delete_with_finalizers "clustercsidriver" "secrets-store.csi.k8s.io" || true
            }
        fi
    fi
    
    # Force cleanup SSCSI-related resources if force flag is enabled (only for SSCSI)
    if [ "$force_flag" = "--force" ] && ([ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]); then
        print_progress "Force cleaning remaining SSCSI-related resources..."
        
        # Force delete deployments and daemonsets first (correct dependency order)
        print_status "Force deleting SSCSI deployments and daemonsets..."
        {
            force_delete_with_finalizers "deployment" "" "app=secrets-store-csi-driver"
            force_delete_with_finalizers "daemonset" "" "app=secrets-store-csi-driver"
        } &
        
        {
            force_delete_with_finalizers "daemonset" "${NAMESPACE}" "app=csi-secrets-store-provider-azure"
        } &
        
        # Wait for deployments/daemonsets to be deleted first
        wait
        
        # Then force delete pods and other resources
        print_status "Force deleting SSCSI pods and resources..."
        {
            force_delete_with_finalizers "pod" "" "app=secrets-store-csi-driver"
            force_delete_with_finalizers "pod" "${NAMESPACE}" "app=csi-secrets-store-provider-azure"
        } &
        
        {
            force_delete_with_finalizers "secretproviderclass" "" ""
            force_delete_with_finalizers "secret" "" "secrets-store.csi.k8s.io/managed=true"
        } &
        
        # Wait for all force cleanup operations to complete
        wait
        
        print_success "Force cleanup of SSCSI resources completed"
    fi
    
    # Clean up operator deployments (these are handled after the operator lifecycle resources)
    print_progress "Cleaning up operator deployments..."
    
    # Delete SSCSI operator deployment (only if no filter or filter is sscsi)
    if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
        oc delete deployment secrets-store-csi-driver-operator -n ${OPERATOR_NAMESPACE} --ignore-not-found=true
    fi
    
    # Clean up OpenShift operators in correct order
    print_progress "Cleaning up OpenShift operators..."
    
    # Helper function to delete CSV with progress bar
    delete_csv_with_progress() {
        local csv="$1"
        local force_mode="$2"
        local current="$3"
        local total="$4"
        
        if [ -z "$csv" ]; then
            return 0
        fi
        
        local csv_name=$(echo "$csv" | cut -d'/' -f2)
        local csv_namespace=$(echo "$csv" | cut -d'/' -f1)
        
        # Show progress bar
        show_csv_progress "$current" "$total" "$csv_name"
        
        if [ "$force_mode" = "true" ]; then
            oc delete "$csv" --ignore-not-found=true --force --grace-period=0 &>/dev/null
            
            # If still stuck, remove finalizers
            if oc get csv "$csv_name" -n "$csv_namespace" &>/dev/null 2>&1; then
                force_delete_with_finalizers "csv" "$csv_namespace" "$csv_name" &>/dev/null
            fi
        else
            oc delete "$csv" --ignore-not-found=true --timeout=30s &>/dev/null || {
                oc delete "$csv" --ignore-not-found=true --force --grace-period=0 &>/dev/null || true
                
                # If still exists, remove finalizers
                if oc get csv "$csv_name" -n "$csv_namespace" &>/dev/null 2>&1; then
                    force_delete_with_finalizers "csv" "$csv_namespace" "$csv_name" &>/dev/null || true
                fi
            }
        fi
    }
    
    # Step 1: Delete CSVs (only when using force mode or for orphaned cleanup)
    # Note: For ESO, CSVs will become orphaned after namespace deletion, but OLM may clean them up
    # For normal ESO cleanup, we follow official procedure which doesn't mention CSV deletion
    # CSVs are cluster-scoped so won't cascade delete with namespace
    
    if [ "$force_flag" = "--force" ]; then
        print_status "Step 1: Deleting ClusterServiceVersions (CSVs) - force mode..."
        
        # Delete ESO CSVs (only if no filter or filter is eso)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
            print_status "Deleting External Secrets Operator CSVs (force mode)..."
            # Get all ESO CSVs
            local eso_csvs
            eso_csvs=$(oc get csv -A -o name | grep -E "(external-secrets|openshift-external-secrets)" || true)
            if [ -n "$eso_csvs" ]; then
                local total_csvs
                total_csvs=$(echo "$eso_csvs" | wc -l | tr -d ' ')
                
                if [ "$total_csvs" -gt 0 ]; then
                    # Force mode: delete one by one with progress bar
                    local current=0
                    while IFS= read -r csv; do
                        if [ -n "$csv" ]; then
                            current=$((current + 1))
                            delete_csv_with_progress "$csv" "true" "$current" "$total_csvs"
                        fi
                    done <<< "$eso_csvs"
                    printf "\r\033[K✅ Deleted %d ESO CSVs (force mode)\n" "$total_csvs"
                else
                    print_status "No ESO CSVs found to delete"
                fi
            else
                print_status "No ESO CSVs found to delete"
            fi
        fi
    else
        # Normal mode: Skip ESO CSV deletion before namespace deletion
        # They're cluster-scoped so won't cascade, but official procedure doesn't mention them
        # We'll clean up orphaned CSVs after namespace deletion if needed
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
            print_status "Skipping ESO CSV deletion (will clean up orphaned CSVs after namespace deletion if needed)"
        fi
    fi
    
    # Delete SSCSI CSVs (only if no filter or filter is sscsi)
    if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
        print_status "Deleting Secrets Store CSI Driver CSVs..."
        # Get all SSCSI CSVs
        local sscsi_csvs
        sscsi_csvs=$(oc get csv -A -o name | grep "secrets-store-csi-driver-operator" || true)
        if [ -n "$sscsi_csvs" ]; then
            local total_csvs
            total_csvs=$(echo "$sscsi_csvs" | wc -l | tr -d ' ')
            
            if [ "$total_csvs" -gt 0 ]; then
                if [ "$force_flag" = "--force" ]; then
                    # Force mode: delete one by one with progress bar
                    local current=0
                    while IFS= read -r csv; do
                        if [ -n "$csv" ]; then
                            current=$((current + 1))
                            delete_csv_with_progress "$csv" "true" "$current" "$total_csvs"
                        fi
                    done <<< "$sscsi_csvs"
                    printf "\r\033[K✅ Deleted %d CSVs (force mode)\n" "$total_csvs"
                else
                    # Normal mode: delete all at once
                    printf "Deleting %d SSCSI CSVs... " "$total_csvs"
                    if [ -n "$sscsi_csvs" ]; then
                        # Convert newlines to spaces for oc delete command
                        local csv_list=$(echo "$sscsi_csvs" | tr '\n' ' ')
                        oc delete $csv_list --ignore-not-found=true --timeout=30s &>/dev/null || true
                    fi
                    printf "✅ Done\n"
                fi
            else
                print_status "No SSCSI CSVs found to delete"
            fi
        else
            print_status "No SSCSI CSVs found to delete"
        fi
    fi
    
    # Step 2: Delete operator lifecycle resources
    # Note: For ESO, Subscriptions/InstallPlans/OperatorGroups will cascade delete with namespace
    # We only need to delete them explicitly for SSCSI (namespace has openshift- prefix, not deleted)
    # Or when using force mode
    
    if [ "$force_flag" = "--force" ]; then
        # Force mode: Explicitly delete all lifecycle resources
        print_status "Step 2: Deleting Subscriptions (force mode)..."
        
        # Delete ESO subscriptions (only if no filter or filter is eso)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
            oc delete subscription openshift-external-secrets-operator -n external-secrets-operator --ignore-not-found=true
        fi
        
        # Delete SSCSI subscriptions (only if no filter or filter is sscsi)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
            oc delete subscription secrets-store-csi-driver-operator -n ${OPERATOR_NAMESPACE} --ignore-not-found=true
        fi
        
        print_status "Step 3: Deleting OperatorGroups (force mode)..."
        
        # Delete ESO OperatorGroups (only if no filter or filter is eso)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
            oc delete operatorgroup external-secrets-operatorgroup -n external-secrets-operator --ignore-not-found=true
        fi
        
        # Delete SSCSI OperatorGroups (only if no filter or filter is sscsi)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
            oc delete operatorgroup secrets-store-csi-driver-operator-og -n ${OPERATOR_NAMESPACE} --ignore-not-found=true
        fi
        
        print_status "Step 4: Deleting InstallPlans (force mode)..."
        
        # Delete ESO InstallPlans (only if no filter or filter is eso)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
            oc delete installplan -n external-secrets-operator --all --ignore-not-found=true
        fi
        
        # Delete SSCSI InstallPlans (only if no filter or filter is sscsi)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
            oc delete installplan -n ${OPERATOR_NAMESPACE} -l operators.coreos.com/secrets-store-csi-driver-operator.openshift-cluster-csi-drivers --ignore-not-found=true
        fi
    else
        # Normal mode: For ESO, skip - they'll cascade delete with namespace
        # For SSCSI, we still need to delete since namespace isn't deleted (openshift- prefix)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
            print_status "Step 2: Deleting SSCSI Subscriptions (namespace preserved)..."
            oc delete subscription secrets-store-csi-driver-operator -n ${OPERATOR_NAMESPACE} --ignore-not-found=true
            
            print_status "Step 3: Deleting SSCSI OperatorGroups (namespace preserved)..."
            oc delete operatorgroup secrets-store-csi-driver-operator-og -n ${OPERATOR_NAMESPACE} --ignore-not-found=true
            
            print_status "Step 4: Deleting SSCSI InstallPlans (namespace preserved)..."
            oc delete installplan -n ${OPERATOR_NAMESPACE} -l operators.coreos.com/secrets-store-csi-driver-operator.openshift-cluster-csi-drivers --ignore-not-found=true
        else
            # ESO: Skip - will cascade delete with namespace
            print_status "Skipping ESO Subscriptions/OperatorGroups/InstallPlans (will cascade delete with namespace)"
        fi
    fi
    
    # Clean up namespaces
    print_progress "Cleaning up namespaces..."
    
    # Delete ESO namespace using official method (oc delete project)
    # Following official Red Hat procedure: Step 3 (after deployments and before CRDs)
    # Only if it doesn't have openshift- prefix and if filtering for ESO or no filter
    if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
        if [[ ! "external-secrets-operator" =~ ^openshift- ]]; then
            if [ "$force_flag" = "--force" ]; then
                print_status "Step 5: Deleting external-secrets-operator namespace (force mode)..."
            else
                print_status "Step 2: Deleting external-secrets-operator namespace (following official procedure)..."
            fi
            oc delete project external-secrets-operator --ignore-not-found=true || true
            # Wait a moment and force delete if still exists
            sleep 2
            if oc get namespace external-secrets-operator &>/dev/null 2>&1; then
                force_delete_namespace "external-secrets-operator"
            fi
            
            # Clean up orphaned ESO CSVs (cluster-scoped, won't cascade delete)
            # Only in normal mode (force mode already handled them)
            if [ "$force_flag" != "--force" ]; then
                print_status "Cleaning up orphaned ESO CSVs..."
                local orphaned_eso_csvs
                orphaned_eso_csvs=$(oc get csv -A -o name 2>/dev/null | grep -E "(external-secrets|openshift-external-secrets)" || true)
                if [ -n "$orphaned_eso_csvs" ]; then
                    local total_orphaned
                    total_orphaned=$(echo "$orphaned_eso_csvs" | wc -l | tr -d ' ')
                    if [ "$total_orphaned" -gt 0 ]; then
                        printf "Deleting %d orphaned ESO CSVs... " "$total_orphaned"
                        local csv_list=$(echo "$orphaned_eso_csvs" | tr '\n' ' ')
                        oc delete $csv_list --ignore-not-found=true --timeout=30s &>/dev/null || true
                        printf "✅ Done\n"
                    fi
                fi
            fi
        else
            print_status "Skipping deletion of namespace 'external-secrets-operator' (openshift- prefix preserved)"
        fi
    fi
    
    # Clean up operator namespace (skip if it has openshift- prefix, only if filtering for SSCSI or no filter)
    if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
        if [[ ! "${OPERATOR_NAMESPACE}" =~ ^openshift- ]]; then
            print_status "Cleaning up operator namespace..."
            oc delete namespace ${OPERATOR_NAMESPACE} --ignore-not-found=true
            force_delete_namespace "${OPERATOR_NAMESPACE}"
        else
            print_status "Skipping deletion of operator namespace '${OPERATOR_NAMESPACE}' (openshift- prefix preserved)"
        fi
    fi
    
    # Step 5: Clean up Custom Resource Definitions (CRDs) - Last step
    print_progress "Cleaning up Custom Resource Definitions (CRDs)..."
    
    # Helper function to delete CRD with proper error handling and single-line progress
    delete_crd() {
        local crd="$1"
        local force_mode="$2"
        local current="$3"
        local total="$4"
        
        if [ -z "$crd" ]; then
            return 0
        fi
        
        # Print progress on single line
        printf "\r\033[K[%d/%d] Deleting CRD: %s" "$current" "$total" "$crd"
        
        if [ "$force_mode" = "true" ]; then
            force_delete_crd "$crd" 10 &>/dev/null
        else
            # Remove finalizers first to prevent hanging
            oc patch crd "$crd" --type json -p='[{"op": "remove", "path": "/metadata/finalizers"}]' --ignore-not-found=true 2>/dev/null || true
            
            # Then delete the CRD
            oc delete crd "$crd" --ignore-not-found=true --timeout=30s &>/dev/null || {
                printf "\r\033[K⚠️  CRD %s deletion timed out or failed (may require manual cleanup)\n" "$crd"
            }
        fi
    }
    
    if [ "$force_flag" = "--force" ]; then
        if [ -z "$operator_filter" ]; then
            print_warning "Force mode: Deleting all SSCSI and ESO CRDs without confirmation"
        elif [ "$operator_filter" = "eso" ]; then
            print_warning "Force mode: Deleting ESO CRDs without confirmation"
        elif [ "$operator_filter" = "sscsi" ]; then
            print_warning "Force mode: Deleting SSCSI CRDs without confirmation"
        fi
        
        # Delete ESO CRDs using official label selector (only if no filter or filter is eso)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
            print_status "Deleting External Secrets Operator CRDs (using official label selector)..."
            # Use official label selector for ESO CRDs
            local eso_crds
            eso_crds=$(oc get customresourcedefinitions.apiextensions.k8s.io -l external-secrets.io/component=controller -o name 2>/dev/null || true)
            if [ -n "$eso_crds" ]; then
                local total_crds
                total_crds=$(echo "$eso_crds" | wc -l | tr -d ' ')
                local current=0
                while IFS= read -r crd; do
                    if [ -n "$crd" ]; then
                        current=$((current + 1))
                        # Extract CRD name from "customresourcedefinition.apiextensions.k8s.io/name" format
                        local crd_name=$(echo "$crd" | cut -d'/' -f2)
                        delete_crd "$crd_name" "true" "$current" "$total_crds"
                    fi
                done <<< "$eso_crds"
                printf "\r\033[K✅ Deleted %d ESO CRDs\n" "$total_crds"
            else
                print_status "No ESO CRDs found to delete"
            fi
        fi
        
        # Delete SSCSI CRDs (only if no filter or filter is sscsi)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
            print_status "Force deleting Secrets Store CSI Driver CRDs..."
            local sscsi_crds
            sscsi_crds=$(oc get crd | grep "secrets-store.csi.x-k8s.io" | awk '{print $1}' || true)
            if [ -n "$sscsi_crds" ]; then
                local total_crds
                total_crds=$(echo "$sscsi_crds" | wc -l | tr -d ' ')
                local current=0
                while IFS= read -r crd; do
                    if [ -n "$crd" ]; then
                        current=$((current + 1))
                        delete_crd "$crd" "true" "$current" "$total_crds"
                    fi
                done <<< "$sscsi_crds"
                printf "\r\033[K✅ Deleted %d SSCSI CRDs\n" "$total_crds"
            fi
        fi
        
        print_success "Force CRD cleanup completed"
    else
        # Delete ESO CRDs using official label selector (only if no filter or filter is eso)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "eso" ]; then
            print_status "Deleting External Secrets Operator CRDs (using official label selector)..."
            # Use official label selector for ESO CRDs
            local eso_crds
            eso_crds=$(oc get customresourcedefinitions.apiextensions.k8s.io -l external-secrets.io/component=controller -o name 2>/dev/null || true)
            if [ -n "$eso_crds" ]; then
                local total_crds
                total_crds=$(echo "$eso_crds" | wc -l | tr -d ' ')
                local current=0
                while IFS= read -r crd; do
                    if [ -n "$crd" ]; then
                        current=$((current + 1))
                        # Extract CRD name from "customresourcedefinitions.apiextensions.k8s.io/name" format
                        local crd_name=$(echo "$crd" | cut -d'/' -f2)
                        delete_crd "$crd_name" "false" "$current" "$total_crds"
                    fi
                done <<< "$eso_crds"
                printf "\r\033[K✅ Deleted %d ESO CRDs\n" "$total_crds"
            else
                print_status "No ESO CRDs found to delete"
            fi
        fi
        
        # Delete SSCSI CRDs (only if no filter or filter is sscsi)
        if [ -z "$operator_filter" ] || [ "$operator_filter" = "sscsi" ]; then
            print_status "Deleting Secrets Store CSI Driver CRDs..."
            local sscsi_crds
            sscsi_crds=$(oc get crd | grep "secrets-store.csi.x-k8s.io" | awk '{print $1}' || true)
            if [ -n "$sscsi_crds" ]; then
                local total_crds
                total_crds=$(echo "$sscsi_crds" | wc -l | tr -d ' ')
                local current=0
                while IFS= read -r crd; do
                    if [ -n "$crd" ]; then
                        current=$((current + 1))
                        delete_crd "$crd" "false" "$current" "$total_crds"
                    fi
                done <<< "$sscsi_crds"
                printf "\r\033[K✅ Deleted %d SSCSI CRDs\n" "$total_crds"
            fi
        fi
    fi
    
    print_success "Kubernetes resources cleaned up!"
}

# Clean up Azure resources
cleanup_azure() {
    print_header "Cleaning Up Azure Resources"
    
    print_warning "This will delete Azure resources with prefix '${AZURE_RESOURCE_PREFIX}' only."
    print_warning "Are you sure? (y/N)"
    read -r response
    if [[ ! "$response" =~ ^[Yy]$ ]]; then
        print_info "Skipping Azure cleanup"
        return 0
    fi
    
    # Check Azure CLI authentication
    print_status "Checking Azure CLI authentication..."
    if ! az account show &> /dev/null; then
        print_error "Azure CLI not authenticated. Please run 'az login' first."
        print_info "Skipping Azure cleanup due to authentication issues"
        return 0
    fi
    
    # Set default resource prefix if not defined
    export AZURE_RESOURCE_PREFIX="${AZURE_RESOURCE_PREFIX:-aro-secrets-}"
    
    # Construct actual resource names with prefix
    export ACTUAL_KEYVAULT_NAME="${AZURE_RESOURCE_PREFIX}${KEYVAULT_NAME}"
    export ACTUAL_SERVICE_PRINCIPAL_NAME="${AZURE_RESOURCE_PREFIX}${SERVICE_PRINCIPAL_NAME}"
    
    print_info "Cleaning up resources with prefix: ${AZURE_RESOURCE_PREFIX}"
    print_info "Key Vault: ${ACTUAL_KEYVAULT_NAME}"
    print_info "Service Principal: ${ACTUAL_SERVICE_PRINCIPAL_NAME}"
    
    # Verify that resources have the prefix before deleting (safety check)
    if [[ ! "${ACTUAL_KEYVAULT_NAME}" =~ ^${AZURE_RESOURCE_PREFIX} ]]; then
        print_error "Key Vault name '${ACTUAL_KEYVAULT_NAME}' does not start with prefix '${AZURE_RESOURCE_PREFIX}'"
        print_error "Refusing to delete - this may not be a resource created by this script"
        return 1
    fi
    
    if [[ ! "${ACTUAL_SERVICE_PRINCIPAL_NAME}" =~ ^${AZURE_RESOURCE_PREFIX} ]]; then
        print_error "Service Principal name '${ACTUAL_SERVICE_PRINCIPAL_NAME}' does not start with prefix '${AZURE_RESOURCE_PREFIX}'"
        print_error "Refusing to delete - this may not be a resource created by this script"
        return 1
    fi
    
    # Clean up role assignments first (before deleting Service Principal or Key Vault)
    print_status "Cleaning up role assignments for Service Principal..."
    
    # Get Service Principal object ID (needed for role assignment cleanup)
    # Only check Service Principals with our prefix
    local sp_object_id=$(az ad sp show --id ${SERVICE_PRINCIPAL_CLIENT_ID} --query "id" -o tsv 2>/dev/null || echo "")
    
    if [ -n "$sp_object_id" ]; then
        # Key Vault scope for role assignments (only for Key Vaults with our prefix)
        local kv_scope="/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${ACTUAL_KEYVAULT_NAME}"
        
        # List and delete role assignments at Key Vault scope
        print_status "Finding role assignments at Key Vault scope..."
        local role_assignment_ids=$(az role assignment list \
            --assignee "${SERVICE_PRINCIPAL_CLIENT_ID}" \
            --scope "${kv_scope}" \
            --query "[].id" \
            -o tsv 2>/dev/null || true)
        
        if [ -n "$role_assignment_ids" ]; then
            echo "$role_assignment_ids" | while read -r assignment_id; do
                if [ -n "$assignment_id" ]; then
                    # Get role name for display
                    local role_name=$(az role assignment show --ids "${assignment_id}" --query "roleDefinitionName" -o tsv 2>/dev/null || echo "Unknown")
                    print_status "Deleting role assignment: ${role_name}"
                    az role assignment delete --ids "${assignment_id}" --only-show-errors 2>/dev/null || true
                fi
            done
        else
            # Alternative: Try to delete specific roles we know were assigned (if listing failed)
            print_status "Attempting to delete known role assignments..."
            for role in "Key Vault Secrets User" "Key Vault Secrets Officer"; do
                az role assignment delete \
                    --assignee "${SERVICE_PRINCIPAL_CLIENT_ID}" \
                    --scope "${kv_scope}" \
                    --role "${role}" \
                    --only-show-errors 2>/dev/null || true
            done
        fi
        
        # Also check for role assignments at resource group scope
        local rg_scope="/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}"
        print_status "Checking for role assignments at resource group scope..."
        local rg_assignment_ids=$(az role assignment list \
            --assignee "${SERVICE_PRINCIPAL_CLIENT_ID}" \
            --scope "${rg_scope}" \
            --query "[].id" \
            -o tsv 2>/dev/null || true)
        
        if [ -n "$rg_assignment_ids" ]; then
            echo "$rg_assignment_ids" | while read -r assignment_id; do
                if [ -n "$assignment_id" ]; then
                    # Get role name for display
                    local role_name=$(az role assignment show --ids "${assignment_id}" --query "roleDefinitionName" -o tsv 2>/dev/null || echo "Unknown")
                    print_status "Deleting role assignment: ${role_name}"
                    az role assignment delete --ids "${assignment_id}" --only-show-errors 2>/dev/null || true
                fi
            done
        fi
    else
        print_warning "Could not retrieve Service Principal object ID - skipping role assignment cleanup"
    fi
    
    # Check if Key Vault exists before trying to clean it (only if it has our prefix)
    print_status "Checking if Key Vault exists..."
    if az keyvault show --name ${ACTUAL_KEYVAULT_NAME} --resource-group ${AZURE_RESOURCE_GROUP} &> /dev/null; then
        # Clean up Key Vault access policies (if using legacy method)
        print_status "Removing Key Vault access policies for Service Principal..."
        az keyvault delete-policy \
            --name ${ACTUAL_KEYVAULT_NAME} \
            --resource-group ${AZURE_RESOURCE_GROUP} \
            --spn ${SERVICE_PRINCIPAL_CLIENT_ID} \
            --only-show-errors 2>/dev/null || true
        
        # Clean up Key Vault secrets
        print_status "Cleaning up Key Vault secrets..."
        az keyvault secret list --vault-name ${ACTUAL_KEYVAULT_NAME} --query "[].name" -o tsv 2>/dev/null | while read -r secret; do
            if [ -n "$secret" ]; then
                az keyvault secret delete --vault-name ${ACTUAL_KEYVAULT_NAME} --name "$secret" --only-show-errors 2>/dev/null || true
            fi
        done
        
        # Clean up Key Vault
        print_status "Cleaning up Key Vault..."
        az keyvault delete --name ${ACTUAL_KEYVAULT_NAME} --resource-group ${AZURE_RESOURCE_GROUP} --only-show-errors 2>/dev/null || true
    else
        print_info "Key Vault '${ACTUAL_KEYVAULT_NAME}' not found or already deleted"
    fi
    
    # Clean up Service Principal (after role assignments are deleted)
    # Only delete if it matches our prefix
    print_status "Cleaning up Service Principal..."
    local sp_display_name=$(az ad sp show --id ${SERVICE_PRINCIPAL_CLIENT_ID} --query "displayName" -o tsv 2>/dev/null || echo "")
    if [ -n "$sp_display_name" ]; then
        if [[ "${sp_display_name}" =~ ^${AZURE_RESOURCE_PREFIX} ]]; then
            az ad sp delete --id ${SERVICE_PRINCIPAL_CLIENT_ID} --only-show-errors 2>/dev/null || print_info "Service Principal not found or already deleted"
        else
            print_warning "Service Principal '${sp_display_name}' does not match prefix '${AZURE_RESOURCE_PREFIX}' - skipping deletion"
            print_info "This Service Principal may have been created manually or by another script"
        fi
    else
        print_info "Service Principal not found or already deleted"
    fi
    
    print_success "Azure resources cleanup completed!"
}

# Clean up local files
cleanup_local() {
    print_header "Cleaning Up Local Files"
    
    # Clean up generated examples
    print_status "Cleaning up generated examples..."
    if [ -d "examples" ]; then
        rm -f examples/*.yaml
    fi
    
    # Clean up temporary files
    print_status "Cleaning up temporary files..."
    find . -name "*.tmp" -delete
    find . -name ".DS_Store" -delete
    
    print_success "Local files cleaned up!"
}

# Show cleanup status
show_cleanup_status() {
    print_header "Cleanup Status"
    
    print_status "Checking Kubernetes resources..."
    echo "Namespaces:"
    oc get namespaces | grep -E "(secrets-store|external-secrets|hello-world)" || echo "  No relevant namespaces found"
    
    echo ""
    echo "ClusterServiceVersions (CSVs):"
    oc get csv -A | grep -E "(secrets-store|external-secrets)" | head -5 || echo "  No relevant CSVs found"
    CSV_COUNT=$(oc get csv -A | grep -E "(secrets-store|external-secrets)" | wc -l)
    if [ "$CSV_COUNT" -gt 5 ]; then
        echo "  ... and $((CSV_COUNT - 5)) more CSVs"
    fi
    
    echo ""
    echo "Custom Resource Definitions (CRDs):"
    oc get crd | grep -E "(secrets-store|external-secrets)" | head -5 || echo "  No relevant CRDs found"
    CRD_COUNT=$(oc get crd | grep -E "(secrets-store|external-secrets)" | wc -l)
    if [ "$CRD_COUNT" -gt 5 ]; then
        echo "  ... and $((CRD_COUNT - 5)) more CRDs"
    fi
    
    echo ""
    echo "Azure resources (with prefix ${AZURE_RESOURCE_PREFIX:-aro-secrets-}):"
    if az account show &> /dev/null; then
        export AZURE_RESOURCE_PREFIX="${AZURE_RESOURCE_PREFIX:-aro-secrets-}"
        export ACTUAL_KEYVAULT_NAME="${AZURE_RESOURCE_PREFIX}${KEYVAULT_NAME}"
        
        # Only show Key Vaults that match our prefix
        az keyvault list --resource-group ${AZURE_RESOURCE_GROUP} --query "[].name" -o tsv 2>/dev/null | while read -r kv; do
            if [ -n "$kv" ] && [[ "$kv" =~ ^${AZURE_RESOURCE_PREFIX} ]]; then
                echo "  Key Vault: $kv"
            fi
        done || echo "  No Key Vaults found (with prefix ${AZURE_RESOURCE_PREFIX})"
        
        # Set prefix for status display
        export AZURE_RESOURCE_PREFIX="${AZURE_RESOURCE_PREFIX:-aro-secrets-}"
        export ACTUAL_SERVICE_PRINCIPAL_NAME="${AZURE_RESOURCE_PREFIX}${SERVICE_PRINCIPAL_NAME}"
        
        az ad sp list --display-name ${ACTUAL_SERVICE_PRINCIPAL_NAME} --query "[].displayName" -o tsv 2>/dev/null | while read -r sp; do
            if [ -n "$sp" ]; then
                echo "  Service Principal: $sp"
            fi
        done || echo "  No Service Principal found (with prefix ${AZURE_RESOURCE_PREFIX})"
    else
        echo "  Azure CLI not authenticated - run 'az login' to check Azure resources"
    fi
}

# Show current configuration
show_configuration() {
    print_header "Current Configuration"
    
    # Ensure Azure values are initialized
    initialize_azure_values
    
    # Fetch Service Principal info if available
    local sp_client_id="${SERVICE_PRINCIPAL_CLIENT_ID:-}"
    if [ -z "$sp_client_id" ] && [ -n "${ACTUAL_SERVICE_PRINCIPAL_NAME:-}" ]; then
        sp_client_id=$(fetch_service_principal_info "${ACTUAL_SERVICE_PRINCIPAL_NAME}" 2>/dev/null || echo "")
        if [ -n "$sp_client_id" ]; then
            export SERVICE_PRINCIPAL_CLIENT_ID="$sp_client_id"
        fi
    fi
    
    # Try to fetch Key Vault from Azure if not already set
    if [ -z "${ACTUAL_KEYVAULT_NAME:-}" ] && [ -n "${AZURE_RESOURCE_GROUP:-}" ]; then
        fetch_keyvault_by_prefix 2>/dev/null || true
    fi
    
    echo "Authentication Method: service-principal (only supported method)"
    echo ""
    
    echo "Resource Prefix: ${AZURE_RESOURCE_PREFIX:-aro-secrets-}"
    echo ""
    
    echo "Service Principal Configuration:"
    echo "• Base Name: ${SERVICE_PRINCIPAL_NAME:-csi-driver-sp}"
    echo "• Actual Name (with prefix): ${ACTUAL_SERVICE_PRINCIPAL_NAME:-${AZURE_RESOURCE_PREFIX:-aro-secrets-}${SERVICE_PRINCIPAL_NAME:-csi-driver-sp}}"
    echo "• Client ID: ${SERVICE_PRINCIPAL_CLIENT_ID:-<not set - will be fetched from Azure>}"
    
    echo ""
    echo "Azure Configuration (fetched from Azure CLI when available):"
    echo "• Subscription: ${AZURE_SUBSCRIPTION_ID:-<not set - will be fetched from Azure CLI>}"
    echo "• Tenant: ${AZURE_TENANT_ID:-<not set - will be fetched from Azure CLI>}"
    echo "• Resource Group: ${AZURE_RESOURCE_GROUP:-<must be set in config.env>}"
    echo "• Location: ${AZURE_LOCATION:-<must be set in config.env>}"
    echo "• Cluster Name: ${AZURE_CLUSTER_NAME:-<must be set in config.env>}"
    echo "• Key Vault Base Name: ${KEYVAULT_NAME:-akv-01}"
    echo "• Key Vault Actual Name (with prefix): ${ACTUAL_KEYVAULT_NAME:-${AZURE_RESOURCE_PREFIX:-aro-secrets-}${KEYVAULT_NAME:-akv-01}}"
    echo "• Key Vault URL: ${KEYVAULT_URL:-https://${ACTUAL_KEYVAULT_NAME:-${AZURE_RESOURCE_PREFIX:-aro-secrets-}${KEYVAULT_NAME:-akv-01}}.vault.azure.net/}"
    echo ""
    echo "Note: Values shown as '<...>' will be fetched dynamically from Azure CLI."
    echo "      Values that must be set: Resource Group, Location, Cluster Name"
}

# Show help
show_help() {
    echo "Secrets Store CSI Driver and External Secrets Operator Management Script"
    echo ""
    echo "Usage: $0 <command> [options]"
    echo ""
    echo "Commands:"
            echo "  show        - Show current configuration"
            echo "  azure       - Setup and validate Azure resources"
            echo "  operator    - Install operators and providers (default)"
            echo "  cleanup     - Clean up resources"
    echo "  validate    - Validate the installation"
    echo "  help        - Show this help message"
            echo ""
            echo "Validate Options:"
            echo "  validate azure      - Validate Azure resources only (no setup)"
            echo "  validate operators - Validate operators installation only"
            echo "  validate all        - Validate everything (default)"
    echo ""
            echo "Install Options:"
            echo "  --sscsi              - Install Secrets Store CSI Driver System Operator + Azure Provider (default)"
            echo "  --eso                - Install External Secrets Operator only"
            echo "  --all                - Install all components (SSCSI + ESO + Azure Provider)"
    echo ""
            echo "Cleanup Options:"
            echo "  cleanup all         - Clean up everything (default)"
            echo "  cleanup operators - Clean up operators (Kubernetes resources only, includes CRDs and force deletion)"
            echo "  cleanup operators --force - Force cleanup with aggressive finalizer removal"
            echo "  cleanup operators --eso - Clean up External Secrets Operator only"
            echo "  cleanup operators --sscsi - Clean up Secrets Store CSI Driver only"
            echo "  cleanup azure       - Clean up Azure resources only"
            echo "  cleanup local       - Clean up local files only"
            echo "  cleanup status      - Show cleanup status"
    echo ""
    echo "Examples:"
            echo "  $0 show                             # Display current configuration"
            echo "  $0 azure                            # Setup and validate Azure resources"
            echo "  $0 validate azure                   # Validate Azure resources only (no setup)"
            echo "  $0 validate operators            # Validate operators installation only"
            echo "  $0 operator                         # Install SSCSI + Azure Provider (default)"
            echo "  $0 operator --sscsi                 # Install SSCSI + Azure Provider (explicit)"
            echo "  $0 operator --eso                   # Install External Secrets Operator only"
            echo "  $0 operator --all                   # Install all components (SSCSI + ESO + Azure Provider)"
            echo "  $0 cleanup all                       # Clean up everything"
            echo "  $0 cleanup operators             # Clean up operators (Kubernetes resources)"
            echo "  $0 cleanup operators --force     # Force cleanup with aggressive finalizer removal"
            echo "  $0 cleanup operators --eso       # Clean up External Secrets Operator only"
            echo "  $0 cleanup operators --sscsi     # Clean up Secrets Store CSI Driver only"
            echo "  $0 cleanup status                   # Show cleanup status"
    echo "  $0 validate                         # Validate installation"
}

# Main script logic
COMMAND="${1:-operator}"
shift  # Remove the command from arguments

# Initialize Azure values from CLI at script start
initialize_azure_values

# Parse arguments for operator command
if [[ "$COMMAND" == "operator" ]]; then
    parse_arguments "$@"
fi

    case "$COMMAND" in
        "show")
            # Show doesn't need cluster auth
            show_configuration
            ;;
        "azure")
            # Azure setup doesn't need cluster auth (only Azure CLI)
            setup_azure_resources
            validate_azure_resources
            ;;
        "cleanup"|"validate"|"operator")
            # Commands that need cluster access - check authentication
            if ! check_cluster_auth; then
                exit 1
            fi
            
            case "$COMMAND" in
    "operator")
        check_prerequisites
        
        # Show installation plan
        print_header "Installation Plan"
        if [[ "$INSTALL_SSCSI" == "true" ]]; then
            print_info "1. Azure Resources Validation (prerequisite check)"
            print_info "2. ✓ Secrets Store CSI Driver System Operator (configuration)"
            print_info "3. ✓ Azure Key Vault Provider (always installed with SSCSI)"
        else
            print_info "1. Azure Resources Validation (skipped - not needed for ESO)"
            print_info "2. ✗ Secrets Store CSI Driver System Operator (skipped)"
            print_info "3. ✗ Azure Key Vault Provider (skipped - requires SSCSI)"
        fi
        
        if [[ "$INSTALL_ESO" == "true" ]]; then
            print_info "4. ✓ External Secrets Operator"
        else
            print_info "4. ✗ External Secrets Operator (skipped)"
        fi
        
        # Step 1: Validate Azure resources (prerequisite check - setup should be done separately)
        if [[ "$INSTALL_SSCSI" == "true" ]]; then
            print_header "Step 1: Validating Azure Resources (Prerequisite)"
            print_info "Azure resources should be set up separately using: ./bin/install azure"
            if ! validate_azure_resources; then
                print_error "Azure resources validation failed. Azure resources are required for SSCSI installation."
                print_info ""
                print_info "Please set up Azure resources first by running:"
                print_info "  ./bin/install azure"
                print_info ""
                print_info "This will create:"
                print_info "  - Azure Key Vault"
                print_info "  - Service Principal with proper RBAC roles"
                print_info "  - Example secrets in Key Vault"
                exit 1
            fi
            print_success "Azure resources validated successfully!"
        else
            print_header "Step 1: Skipping Azure Resources (not needed for ESO-only installation)"
        fi
        
        # Step 2: Configure operators based on options
        if [[ "$INSTALL_SSCSI" == "true" ]]; then
            print_header "Step 2: Secrets Store CSI Driver Configuration"
            configure_operator
            install_azure_provider  # Always install Azure provider with SSCSI
        fi
        
        if [[ "$INSTALL_ESO" == "true" ]]; then
            if [[ "$INSTALL_SSCSI" == "true" ]]; then
                print_header "Step 3: External Secrets Operator Installation"
            else
                print_header "Step 2: External Secrets Operator Installation"
            fi
            install_external_secrets_operator
        fi
        
        # Test resources are created separately via examples or webapp deployment
        
        validate_installation
        show_post_install_info
        ;;
    "cleanup")
        CLEANUP_TYPE="${1:-all}"
        FORCE_FLAG=""
        OPERATOR_FILTER=""
        
        # Parse remaining arguments for flags
        shift || true
        while [ $# -gt 0 ]; do
            case "$1" in
                "--force")
                    FORCE_FLAG="--force"
                    print_warning "Force cleanup enabled - will aggressively remove finalizers and force delete resources"
                    ;;
                "--eso")
                    OPERATOR_FILTER="eso"
                    ;;
                "--sscsi")
                    OPERATOR_FILTER="sscsi"
                    ;;
                *)
                    print_error "Unknown flag: $1"
                    echo "Valid flags: --force, --eso, --sscsi"
                    exit 1
                    ;;
            esac
            shift || true
        done
        
        case "$CLEANUP_TYPE" in
            "all")
                cleanup_kubernetes "$FORCE_FLAG" "$OPERATOR_FILTER"
                cleanup_azure
                cleanup_local
                ;;
            "operators")
                cleanup_kubernetes "$FORCE_FLAG" "$OPERATOR_FILTER"
                ;;
            "azure")
                cleanup_azure
                ;;
            "local")
                cleanup_local
                ;;
            "status")
                show_cleanup_status
                ;;
            *)
                print_error "Unknown cleanup option: $CLEANUP_TYPE"
                echo "Valid options: all, operators, azure, local, status"
                echo "Use --force flag for aggressive cleanup: cleanup operators --force"
                echo "Use --eso or --sscsi to filter by operator: cleanup operators --eso"
                exit 1
                ;;
        esac
        ;;
    "validate")
        VALIDATE_TYPE="${1:-all}"
        case "$VALIDATE_TYPE" in
            "azure")
                validate_azure_resources
                ;;
            "operators")
        validate_installation
                ;;
            "all")
                validate_azure_resources
                validate_installation
                ;;
            *)
                print_error "Unknown validate option: $VALIDATE_TYPE"
                echo "Valid options: azure, operators, all"
                exit 1
                ;;
        esac
        ;;
            esac
        ;;
    "help"|*)
        show_help
        ;;
esac


